<!DOCTYPE html>
<html lang="en">
	<head>
		<style>
			body {
				background-color: black;
				color: white;
				font-family: Arial, sans-serif;
				min-width: 100vw;
			}
			div {
				border-radius: 8px;
				background-color: rgb(30, 30, 30);
			}
		</style>
	</head>
	<body>
		<script src="audioEditor.js"></script>
		<script src="audioExporter.js"></script>
		Volume (<a id="la">100</a>%): <input type="range" id="vol" min="0" max="10" step="0.01" style="width: 100%">
		<h1>Audio Editor</h1>
		<p>I've been trying to think of ways to refine it, and I've also been watching YouTube videos, which is the reason why I barely worked on anything. But finally, the audio editor is here!</p>
		Current Audio File: <input type="file" id="aud" accept=".wav, .mp3, .ogg, .flac, .aac, .weba">
		<script>
			const audioContext = new (window.AudioContext || window.webkitAudioContext)();
			const audioInput = document.getElementById("aud"), ed = document.getElementById("editor"), volume = document.getElementById("vol"), label = document.getElementById("la");
			let exporters = [];
			let sharedBuffer = null, src = null, whenPlayed = 0, playing = false, timeline = null, startAt = 0, bbb = 0;
			let gainNode = audioContext.createGain();
			gainNode.connect(audioContext.destination);
			gainNode.gain.value = 1;
			volume.oninput = function() {
				const x = +volume.value;
				if (x > 0.9 && x < 1) volume.value = 1;
				label.textContent = x * 100;
				gainNode.gain.value = x;
			}
			function tick() {
				if (timeline && playing) {
					const x = Date.now() - whenPlayed;
					timeline.setAttribute("x", x / 1000 * sharedBuffer.sampleRate / 480 + bbb);
				}
				requestAnimationFrame(() => tick());
			}
			function playSound() {
				if (!sharedBuffer) return;
				if (src) {
					src.onended = function() {};
					src.stop();
				}
				src = audioContext.createBufferSource();
				src.buffer = sharedBuffer;
				src.connect(audioContext.destination);
				src.start(0, startAt);
				whenPlayed = Date.now();
				playing = true;
				if (timeline) timeline.setAttribute("fill", "red");
				src.onended = function() {
					playing = false;
					timeline.setAttribute("fill", "none");
				}
			}
			function loadDiv(exp) {
				const v = document.createElement("div");
				const x = document.createElementNS("http://www.w3.org/2000/svg", "svg");
				document.body.appendChild(v);
				v.appendChild(x);
				x.setAttribute("width", exp.audioData.length / 480);
				v.style.width = (exp.audioData.length / 480) + "px";
				x.setAttribute("height", 200);
				const n = document.createElementNS("http://www.w3.org/2000/svg", "path");
				x.appendChild(n);
				n.setAttribute("fill", "white");
				n.setAttribute("stroke-width", 1);
				let data = "M 0,100 ";
				const len = exp.audioData.length, y = exp.audioData;
				if (y instanceof Float32Array || y instanceof Float64Array) {
					for (let i = 0, j = 0; i < len; i += 480, j++) {
						data += "L " + j + "," + (100 + y[i] * 100) + " ";
					}
				} else if (y instanceof Uint8Array) {
					for (let i = 0, j = 0; i < len; i += 480, j++) {
						data += "L " + j + "," + (100 + y[i] / 2.55) + " ";
					}
				} else if (y instanceof Int16Array) {
					for (let i = 0, j = 0; i < len; i += 480, j++) {
						data += "L " + j + "," + (100 + y[i] / 327.68) + " ";
					}
				}
				n.setAttribute("d", data);
				v.appendChild(document.createElement("br"));
				const play = document.createElement("button");
				play.textContent = "Play Sound";
				v.appendChild(play);
				timeline = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timeline.setAttribute("height", 200);
				timeline.setAttribute("width", 2);
				timeline.setAttribute("fill", "none");
				timeline.setAttribute("x", 0);
				x.appendChild(timeline);
				play.onclick = () => {
					startAt = 0;
					bbb = 0;
					playSound();
				}
				x.onclick = function(eve) {
					startAt = (eve.clientX - x.getBoundingClientRect().x) / 480 * exporters[0].sampleRate / 10000;
					bbb = startAt * 100;
					playSound();
				}
			}
			audioInput.oninput = function(eve) {
				if (eve.target.files.length === 0) return;
				if (exporters.length === 1) {
					alert("You can only edit one sound at a time! This limitation will likely be lifted in the future.");
					return;
				}
				const firstFile = eve.target.files[0];
				const fileReader = new FileReader();
				fileReader.onload = async function(event) {
					try {
						sharedBuffer = await audioContext.decodeAudioData(event.target.result);
						const channel = sharedBuffer.getChannelData(0);
						exporters.push(new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32));
						loadDiv(exporters[exporters.length - 1]);
					} catch (err) {
						alert("The audio could not be properly loaded! Due to the strip-aways from viewing metadata that are unhelpful, we cannot provide much info on what exactly failed.");
						console.log(err.message + err.stack);
					}
				}
				fileReader.readAsArrayBuffer(firstFile);
			}
			tick();
		</script>
	</body>
</html>
