<!DOCTYPE html>
<html lang="en">
	<head>
		<style>
			body {
				background-color: black;
				color: white;
				font-family: Arial, sans-serif;
				min-width: 100vw;
			}
			div {
				border-radius: 8px;
				background-color: rgb(30, 30, 30);
			}
		</style>
	</head>
	<body>
		<script src="audioEditor.js"></script>
		<script src="audioExporter.js"></script>
		<script src="audioEffects.js"></script>
		<script src="audioLSAC.js"></script>
		<script src="audioFBAC.js"></script>
		<script src="lame.min.js"></script>
		<script src="audioEncoders.unpkg.js"></script>
		<script src="flacjs/libflac.min.js"></script>
		<script src="opus/libopus.wasm.js"></script>
		Volume (<a id="la" style="width: 100px">100</a>%): <input type="range" id="vol" min="0" max="10" step="0.01" value="1" style="width: 100%"><br>
		Volume Multiplier (<a id="la2" style="width: 100px">100</a>%): <input type="range" id="vol2" min="0" max="10" step="0.01" value="1" style="width: 100%"><br>
		<a id="selectlabel">Selecting A Certain Region?</a> <input type="checkbox" id="select">
		<h1>Audio Editor</h1>
		<p>I've been trying to think of ways to refine it, and I've also been watching YouTube videos, which is the reason why I barely worked on anything. But finally, the audio editor is here!</p>
		Current Audio File: <input type="file" id="aud" accept=".wav, .mp3, .ogg, .flac, .aac, .weba, .m4v, .m4a, .mp4, .3gp, .3g2, .webm, .lsac, .fbac" multiple><br>
		<button id="which">Decode The Audio File</button> <button id="loadblank">Load Blank Audio</button>
		<script>
			const audioContext = new (window.AudioContext || window.webkitAudioContext)();
			const audioInput = document.getElementById("aud"), volume = document.getElementById("vol"), label = document.getElementById("la"), volume2 = document.getElementById("vol2"), label2 = document.getElementById("la2"), selectBox = document.getElementById("select"), selectLabel = document.getElementById("selectlabel");
			let exporters = null;
			let sharedBuffer = null, src = null, whenPlayed = 0, playing = false, timeline = null, timelineBegin = null, timelineEnd = null, highlight = null, timelineBeginNum = 0, timelineEndNum = 0, timelineEndNumCache = 0, timelineBeginAudio = 0, timelineEndAudio = 0, timelineIter = -1, isPressingShift = false, startAt = 0, bbb = 0, ed = null, div = null, data = null, dataSecond = null, skipSample = 480, volumeWarning = true, prevIntervalID = null, xOff, skipSampleUnround = 480;
			let gainNode = audioContext.createGain();
			const interpretFiles = document.getElementById("which");
			const loadBlank = document.getElementById("loadblank");
			let whichInterpret = false;
			selectBox.oninput = function() {
				isPressingShift = selectBox.checked;
			}
			interpretFiles.onclick = function() {
				whichInterpret = !whichInterpret;
				interpretFiles.textContent = whichInterpret ? "Treat File Data As Audio" : "Decode The Audio File";
				audioInput.accept = whichInterpret ? "*" : ".wav, .mp3, .ogg, .flac, .aac, .weba, .m4v, .m4a, .mp4, .3gp, .3g2, .webm, .lsac, .fbac";
			}
			gainNode.connect(audioContext.destination);
			gainNode.gain.value = 1;
			volume.oninput = function() {
				if (volumeWarning) {
					volumeWarning = false;
					alert("Moving the knob to the right can cause incredibly loud results! Please use the volume sliders responsibly and ethically, as these are very experimental features.");
					volume.value = 1;
				}
				let x = +volume.value;
				if (x > 0.9 && x < 1.1) x = volume.value = 1;
				label.textContent = Math.round(x * 100);
				label.textContent = label.textContent;
				gainNode.gain.value = x * +volume2.value;
				if (x >= +volume.max / 1.1) {
					volume.max *= 10;
					volume.disabled = true;
					document.onmouseup = function() {
						volume.disabled = false;
						document.onmouseup = null;
					}
				}
			}
			volume2.oninput = function() {
				if (volumeWarning) {
					volumeWarning = false;
					alert("Moving the knob to the right can cause incredibly loud results! Please use the volume sliders responsibly and ethically, as these are very experimental features.");
					volume.value = 1;
				}
				let x = +volume2.value;
				if (x > 0.9 && x < 1.1) x = volume2.value = 1;
				label2.textContent = Math.round(x * 100);
				label2.textContent = label2.textContent;
				gainNode.gain.value = x * +volume.value;
				if (x >= +volume2.max / 1.1) {
					volume2.max *= 10;
					volume2.disabled = true;
					document.body.onmouseup = function() {
						volume2.disabled = false;
						document.body.onmouseup = null;
					}
				}
			}
			function tick() {
				if (timeline && playing) {
					let x = (Date.now() - whenPlayed) / 1000;
					if (sampleSkip === 1) {
						timeline.setAttribute("x", x * sharedBuffer.sampleRate / sampleSkip + bbb - window.pageXOffset);
					} else {
						timeline.setAttribute("x", x * sharedBuffer.sampleRate / sampleSkip + bbb);
					}
					if (timelineEndNum !== 0 && x > timelineEndNumCache) {
						playing = false;
						src.stop();
					}
				}
				requestAnimationFrame(() => tick());
			}
			function playSound() {
				if (!sharedBuffer) return;
				if (src) {
					src.onended = function() {};
					if (playing) {
						try {
							src.stop();
						} catch {};
					}
				}
				src = audioContext.createBufferSource();
				src.buffer = sharedBuffer;
				src.connect(gainNode);
				startAt += timelineBeginNum / div.clientWidth * sharedBuffer.duration;
				src.start(0, startAt);
				whenPlayed = Date.now() - startAt * 1000;
				playing = true;
				if (timeline) timeline.setAttribute("fill", "red");
				src.onended = function() {
					playing = false;
					timeline.setAttribute("fill", "none");
				}
			}
			function generateWaveform(exp) {
				let data2 = ["M 0,100 L 0,100"];
				const len = exp.audioData.length, y = exp.audioData;
				let prev = 0, val;
				let ep = 0.004;
				val = y[0];
				let b = 0;
				for (let i = 0, j = 0; i < len; i = b, j++) {
					b = i + sampleSkip;
					if (Math.abs(prev - val) >= ep) {
						data2.push("L " + j + "," + Math.round(100 + val * 100));
						val = y[b] || 0;
					}
					prev = y[i];
				}
				data2.push("L " + (len / sampleSkip) + ",100");
				return data2.join(" ");
			}
			function loadDiv(exp, blank = false) {
				if (prevIntervalID !== undefined) clearInterval(prevIntervalID);
				const v = document.createElement("div");
				const x = document.createElementNS("http://www.w3.org/2000/svg", "svg");
				document.body.appendChild(v);
				v.appendChild(x);
				x.setAttribute("width", exp[0].audioData.length / sampleSkip);
				v.style.width = (exp[0].audioData.length / sampleSkip) + "px";
				x.setAttribute("height", 200);
				const n = document.createElementNS("http://www.w3.org/2000/svg", "path");
				x.appendChild(n);
				n.setAttribute("fill", "white");
				n.setAttribute("stroke-width", 1);
				if (blank) data = ""; else data = generateWaveform(exp[0]);
				n.setAttribute("d", data);
				v.appendChild(document.createElement("br"));
				const play = document.createElement("button");
				play.textContent = "Play Sound";
				v.appendChild(play);
				timeline = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timeline.setAttribute("height", 200);
				timeline.setAttribute("width", 2);
				timeline.setAttribute("fill", "none");
				timeline.setAttribute("x", 0);
				timelineBegin = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timelineBegin.setAttribute("height", 200);
				timelineBegin.setAttribute("width", 2);
				timelineBegin.setAttribute("fill", "none");
				timelineBegin.setAttribute("x", 0);
				timelineEnd = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timelineEnd.setAttribute("height", 200);
				timelineEnd.setAttribute("width", 2);
				timelineEnd.setAttribute("fill", "none");
				timelineEnd.setAttribute("x", 0);
				highlight = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				highlight.setAttribute("height", 200);
				highlight.setAttribute("width", 2);
				highlight.setAttribute("fill", "none");
				highlight.setAttribute("x", 0);
				x.appendChild(timeline);
				x.appendChild(timelineBegin);
				x.appendChild(timelineEnd);
				x.appendChild(highlight);
				let n2 = null;
				if (exp.length > 1 && confirm("Would you like the second channel to be displayed?")) {
					n2 = document.createElementNS("http://www.w3.org/2000/svg", "path");
					x.appendChild(n2);
					n.setAttribute("fill", "white");
					n2.setAttribute("fill", "red");
					n2.setAttribute("stroke-width", 1);
					n.setAttribute("fill-opacity", 0.5);
					n2.setAttribute("fill-opacity", 0.5);
					if (blank) dataSecond = ""; else dataSecond = generateWaveform(exp[1]);
					n2.setAttribute("d", dataSecond);
					alert("White waveform = left hearing, red waveform = right hearing. Note: If parts of the waveform are a light red, this means the audio track sounds nearly identical for both hearing sides.");
				}
				let bpmMarks = [];
				function restartSelect() {
					timelineIter = -1;
					timelineBegin.setAttribute("fill", "none");
					timelineBegin.setAttribute("x", 0);
					timelineEnd.setAttribute("fill", "none");
					timelineEnd.setAttribute("x", 0);
					highlight.setAttribute("fill", "none");
					highlight.setAttribute("x", 0);
					timelineBeginNum = 0;
					timelineEndNum = 0;
					timelineEndNumCache = 0;
					timelineBeginAudio = 0;
					timelineEndAudio = 0;
				}
				play.onclick = () => {
					startAt = 0;
					bbb = 0;
					playSound();
				}
				//document.body.onclick = restartSelect;
				function playWithTimeline(eve) {
					let clickX = eve.clientX - /*(timelineBeginNum ? (v.getBoundingClientRect().x - window.pageXOffset) :*/ (xOff - window.scrollX);
					if (isPressingShift) {
						timelineIter++;
						switch (timelineIter) {
							case 0: {
								timelineBegin.setAttribute("x", clickX);
								timelineBegin.setAttribute("fill", "#00AAFF");
								timelineBeginNum = clickX;
								timelineBeginAudio = timelineBeginNum * sampleSkip;
								break;
							}
							case 1: {
								timelineEnd.setAttribute("x", clickX);
								timelineEnd.setAttribute("fill", "#00AAFF");
								highlight.setAttribute("fill", "#00AAFF");
								highlight.setAttribute("fill-opacity", 0.3);
								timelineEndNum = clickX;
								if (timelineEndNum < timelineBeginNum) {
									const temp = timelineEndNum;
									timelineEndNum = timelineBeginNum;
									timelineBeginNum = temp;
								}
								timelineEndNumCache = timelineEndNum / div.clientWidth * sharedBuffer.duration;
								timelineEndAudio = timelineEndNum * sampleSkip;
								highlight.setAttribute("x", timelineBeginNum);
								highlight.setAttribute("width", timelineEndNum - timelineBeginNum);
								break;
							}
							case 2: {
								restartSelect();
								break;
							}
						}
						return;
					}
					const relativeX = clickX / x.clientWidth;
					startAt = relativeX * sharedBuffer.duration; // Time in seconds

					if (timelineBeginNum) startAt = 0;
					playSound();
				}
				x.onclick = playWithTimeline;
				const label3 = document.createElement("a");
				const co = document.createElement("input");
				label3.textContent = "View at Sample-Level";
				v.appendChild(label3);
				co.type = "checkbox";
				v.appendChild(co);
				co.oninput = function() {
					if (co.checked) {
						sampleSkip = 1;
						x.setAttribute("width", exp[0].audioData.length);
						v.style.width = exp[0].audioData.length + "px";
					} else {
						sampleSkip = 480;
						if (!data) data = generateWaveform(exp[0]);
						x.setAttribute("width", exp[0].audioData.length / sampleSkip);
						x.style.marginLeft = "0px";
						v.style.width = (exp[0].audioData.length / sampleSkip) + "px";
						n.setAttribute("d", data);
						if (n2) n2.setAttribute("d", dataSecond);
					}
				}
				let count = 0;
				let yu = exp[0].audioData.length;
				window.onkeydown = function(key) {
					if (key.key === " ") {
						const s = isPressingShift;
						isPressingShift = false;
						playWithTimeline({clientX: /*(timelineIter === -1 ? (*/ v.getBoundingClientRect().x - window.pageXOffset /*) : Math.max(xOff - window.pageXOffset, (v.getBoundingClientRect().x - window.pageXOffset)))*/});
						isPressingShift = s;
					}
				}
				prevIntervalID = setInterval(function() {
					xOff = v.getBoundingClientRect().x + window.pageXOffset;
				}, 1000);
				v.appendChild(document.createElement("br"));
				const opt = document.createElement("select");
				const apply = document.createElement("button");
				const params = document.createElement("div");
				const bpm = document.createElement("button");
				v.appendChild(bpm);
				bpm.textContent = "Label BPM";
				bpm.onclick = function() {
					if (bpmMarks.length > 0) {
						for (const b of bpmMarks) b.remove();
					}
					bpmMarks = [];
					const bpmNum = Number(prompt("What is the amount of beats per minute of this track?") || NaN);
					if (!isNaN(bpmNum)) {
						if (bpmNum > 2400) {
							alert("There are too many BPM.");
							return;
						} else if (bpmNum <= 1) {
							alert("The amount of BPM is too low.")
							return;
						}
						const inc = (60 / bpmNum) * (div.clientWidth / sharedBuffer.duration);
						const data1 = document.createElementNS("http://www.w3.org/2000/svg", "path");
						data1.setAttribute("stroke", "yellow");
						data1.setAttribute("fill", "none");
						data1.setAttribute("width", div.clientWidth);
						data1.setAttribute("height", "200");
						const data2 = document.createElementNS("http://www.w3.org/2000/svg", "path");
						data2.setAttribute("stroke", "orange");
						data1.setAttribute("fill", "none");
						data2.setAttribute("width", div.clientWidth);
						data1.setAttribute("height", "200");
						let data1Data = [], data2Data = [];
						const wid = div.clientWidth;
						for (let i = 0, j = 0; i < wid; i += inc, j++) {
							if ((j & 3) === 0) data1Data.push(`M${i},0 V200`); else data2Data.push(`M${i},0 V200`);
						}
						data1.setAttribute("d", data1Data.join(" "));
						data2.setAttribute("d", data2Data.join(" "));
						x.appendChild(data1);
						x.appendChild(data2);
						bpmMarks.push(data1, data2);
					}
				}
				{
					const label = document.createElement("a");
					label.textContent = "Effect To Apply: ";
					let option = document.createElement("option");
					option.textContent = "Please select an effect";
					option.value = "placeholder";
					v.appendChild(label);
					v.appendChild(opt);
					opt.appendChild(option);
					for (let effect of effectsList) {
						option = document.createElement("option");
						option.textContent = effect[0];
						option.value = effect[4];
						opt.appendChild(option);
					}
					v.appendChild(params);
					apply.textContent = "Apply";
					v.appendChild(apply);
					let currentSelected = null, paramElements = null, effect;
					apply.onclick = async function() {
						if (currentSelected) {
							apply.disabled = true;
							for (const expor of exp) {
								const values = [expor, ...paramElements.map((x, i) => {
									if (x.type === "checkbox") {
										return effect[5][i](x.checked);
									} else {
										return effect[5][i](x.value);
									}
								})];
								if (timelineBeginAudio !== 0) values[0] = {audioData: expor.audioData.subarray(timelineBeginAudio, timelineEndAudio), sampleRate: expor.sampleRate};
								const le = values[0].audioData.length;
								await effects[effect[4]](...values);
								if (timelineBeginAudio !== 0) {
									if (values[0].audioData.buffer !== expor.audioData.buffer) {
										if (values[0].audioData.length === timelineEndAudio - timelineBeginAudio) {
											expor.audioData.set(values[0].audioData, timelineBeginAudio);
										} else {
											const data = new Float32Array(values[0].audioData.length + expor.audioData.length - le);
											data.set(expor.audioData.subarray(0, timelineBeginAudio), 0);
											data.set(values[0].audioData, timelineBeginAudio);
											data.set(expor.audioData.subarray(timelineEndAudio, expor.audioData.length), values[0].audioData.length + timelineBeginAudio);
											expor.audioData = data;
											//timelineEndAudio = values[0].audioData.length - timelineBeginAudio;
										}
									}
								}
							}
							data = generateWaveform(exp[0]);
							if (n2) dataSecond = generateWaveform(exp[1]);
							sharedBuffer = audioContext.createBuffer(exp.length, exp[0].audioData.length, exp[0].sampleRate);
							const ref = sharedBuffer.getChannelData(0);
							ref.set(exp[0].audioData);
							if (exp.length === 2) {
								const ref2 = sharedBuffer.getChannelData(1);
								ref2.set(exp[1].audioData);
							}
							x.setAttribute("width", exp[0].audioData.length / sampleSkip);
							v.style.width = (exp[0].audioData.length / sampleSkip) + "px";
							n.setAttribute("d", data);
							if (n2) n2.setAttribute("d", dataSecond);
							apply.disabled = false;
							x.onclick = playWithTimeline; // Reset playing function, just in case browsers like Chrome misbehave every time an effect is applied
							yu = exp[0].audioData.length;
						}
					}
					opt.oninput = function() {
						effect = effectsList.find(x => x[4] === opt.value);
						currentSelected = effect;
						if (effect) {
							params.innerHTML = effect[1] + "<br>" + effect[2];
							paramElements = new Array(effect[3]);
							for (let i = 0; i < paramElements.length; i++) {
								paramElements[i] = document.getElementById(effect[4] + i);
							}
						} else {
							params.innerHTML = "";
							paramElements = null;
						}
					}
				}
				v.appendChild(document.createElement("br"));
				let exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as WAV";
				exportBtn.onclick = function() {
					const metadata = {};
					const author = prompt("Who is the author of this audio? (e.g. \"John Smith\") Leave the input blank if you don't want the author to be specified.");

					if (author === "" || author === undefined || author === null) return;
					const name = prompt("What is the name of this audio? (e.g. \"Electro Dance (Techno Mix)\") Leave the input blank if you don't want the name to be specified.");
					const genre = prompt("What is the genre of this audio? (e.g. \"Techno\") Leave the input blank if you don't want the genre to be specified.");
					const notes = prompt("Any notes or comments for this audio? (e.g. \"This audio is super cool\") Leave the input blank if you don't have any notes or comments.");

					const software = prompt("What software did you use to create this audio? (e.g. \"UnnamedBruh's Audio Editor\") If input is \"UAE\" without quotes, this software's name will be appended to the audio metadata.");

					if (author) metadata["IART"] = author;
					if (name) metadata["INAM"] = name;
					if (genre) metadata["IGNR"] = genre;
					if (notes) metadata["ICMT"] = notes;
					if (software) metadata["ISFT"] = software === "UAE" ? "UnnamedBruh's Audio Editor" : software;

					const encodeBits = prompt("What are the exporting settings of the audio? (0 = 8-bit integer. 1 = 16-bit integer. 2 = 32-bit integer. 3 = 32-bit float. 4 = 64-bit float. 5 = mu-law. 6 = a-law.");

					const exporters2 = timelineBeginAudio ? {audioData: exporters[0].audioData.subarray(timelineBeginAudio, timelineEndAudio), sampleRate: exporters[0].sampleRate, bits: exporters[0].bits, encoding: exporters[0].encoding, convertToWav: exporters[0].convertToWav} : exporters[0];
					const oldBits = exporters2.bits;
					if (encodeBits == 0) {
						exporters2.bits = 8;
						exporters2.encoding = "pcm";
					} else if (!encodeBits || encodeBits == 1) {
						exporters2.bits = 16;
						exporters2.encoding = "pcm";
					} else if (encodeBits == 2) {
						exporters2.bits = 32;
						exporter2s.encoding = "pcm";
					} else if (encodeBits == 3) {
						exporters2.bits = 32;
						exporters2.encoding = "pcmf32";
					} else if (encodeBits == 4) {
						exporters2.bits = 64;
						exporters2.encoding = "pcmf64";
					} else if (encodeBits == 5) {
						exporters2.encoding = "mulaw";
					} else if (encodeBits == 6) {
						exporters2.encoding = "alaw";
					}
					
					const blob = exporters2.convertToWav(metadata, exporters.length > 1 ? exporters[1].audioData : undefined);

					exporters2.bits = encodeBits;

					const link = document.createElement("a");
					link.download = (name || "exportedAudio") + ".wav";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as MP3";
				exportBtn.onclick = async function() {
					function floatTo16BitPCM(float32Array, channels) {
						const len = float32Array.length / channels;
						const buffer = new Int16Array(len);
						let s = 0;
						if (channels === 1) {
							for (let i = 0; i < len; i++) {
								s = float32Array[i];
								buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						} else {
							for (let i = 0, j = 0; i < len; i++, j+=channels) {
								s = float32Array[j];
								buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						}
						return buffer;
					}

					let sampleRate = exporters[0].sampleRate;
					const kbps = Math.ceil(Number(prompt("What is the KBPS (Kilobits Per Second) of the MP3 audio? (e.g. 64, 80, 96, 128, 192, 256, 320)")) / 16) * 16;
					if (kbps === 0 || isNaN(kbps) || kbps === undefined || kbps === null) return;

					const qual = Math.min(9, Math.max(0, prompt("What is the VBR (Variable BitRate) of the MP3 audio? (between 0 and 9. 0 = best quality and slower encoding, 9 = worst quality and faster encoding, 3 = balanced)") ?? 3));

					const channels = (exporters.length === 2) ? 2 : 1;
					const shouldSplit = channels !== 2 && confirm("Should the same buffer be split into two channels? (If so, the audio may sound a bit choppier)");

					const lossTimes = Number(prompt("How many times should the same audio be re-encoded? (for glitch-art audio)") || 1);

					let blob;

					for (let i = 0; i < lossTimes; i++) {
						let buffer = i === 0 ? exporters.map(exp => timelineBeginAudio ? exp.audioData.subarray(timelineBeginAudio, timelineEndAudio) : exp.audioData) : await audioContext.decodeAudioData(await blob.arrayBuffer());
						let altRate = buffer.sampleRate;
						if (i > 0) {
							if (buffer.numberOfChannels === 2) buffer = [buffer.getChannelData(0), buffer.getChannelData(1)]; else buffer = [buffer.getChannelData(0), buffer.getChannelData(0)];
						}
						const mp3Encoder = new lamejs.Mp3Encoder(channels, i === 0 ? sampleRate : altRate, kbps, qual);

						let mp3Data = [];

						let pcmData = [floatTo16BitPCM(buffer[0], channels === 2 && !shouldSplit ? 2 : 1)];
						const len = pcmData[0].length;
						if (channels === 1) pcmData = [pcmData[0], pcmData[0]]; else pcmData = [pcmData[0], floatTo16BitPCM(buffer[1], 2)];
						const len2 = len - 1152;
						let xx;

						for (let i = 0; i < len2; i += 1152) {
							xx = i > len2 ? len : i + 1152;
							const chunk = [pcmData[0].subarray(i, xx), pcmData[1].subarray(i, xx)];

							// For mono input, pass chunk for both channels if needed
							const mp3Chunk = mp3Encoder.encodeBuffer(chunk[0], chunk[1]);
							mp3Data.push(mp3Chunk);
						}

						mp3Data.push(mp3Encoder.flush());
						blob = new Blob(mp3Data, { type: "audio/mp3" });
					}

					const link = document.createElement("a");
					link.download = "exportedAudio.mp3";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as OGG (Vorbis format, wasm-media-encoders)";
				exportBtn.onclick = async function() {
					try {
						const vbr = Number(prompt("How high can the quality of the audio be? (-1.0 = worst quality, big differences, low sizes; 10.0 = best quality, nearly-neglible differences, higher sizes; 4.0 = balanced quality, minimal differences, medium sizes)") ?? 4.0) ?? 4.0;

						let blob;
						const split = exporters.length !== 2 && !!confirm("Should the audio be split into two separate channels?");

						const times = Number(prompt("How many times would the audio be re-encoded?") || 1) || 1;

						for (let i = 0; i < times; i++) {
							const encoder = await WasmMediaEncoder.createOggEncoder();

							let buffer = i === 0 ? exporters.map(exp => timelineBeginAudio ? exp.audioData.subarray(timelineBeginAudio, timelineEndAudio) : exp.audioData) : await audioContext.decodeAudioData(await blob.arrayBuffer());
							let altRate = buffer.sampleRate;
							if (i > 0) {
								if (buffer.numberOfChannels === 2) buffer = [buffer.getChannelData(0), buffer.getChannelData(1)]; else buffer = [buffer.getChannelData(0)];
							}

							encoder.configure({
								sampleRate: i === 0 ? exporters[0].sampleRate : altRate,
								channels: Math.min(2, buffer.length + split),
								vbrQuality: vbr,
							});
							
							const encodedData = encoder.encode(split || buffer.length === 2 ? [buffer[0], buffer[1] || buffer[0]] : [buffer[0]]);
							const encodedCopy = new Uint8Array(encodedData).buffer;
							const finalData = encoder.finalize();

							blob = new Blob([encodedCopy, finalData], { type: "audio/ogg" });
						}

						const link = document.createElement("a");
						link.download = "exportedAudio.ogg";
						link.href = URL.createObjectURL(blob);
						link.click();
						link.remove();
					} catch (err) {
						alert("It seems like the OGG Vorbis codec is supported, but not yet available. READ BELOW:\n\nA network is required to export your audio into the OGG format. The encoder itself is stored in an online module server (UNPKG.com), then loaded into this audio editor. (This means your audio track or other invaluable information isn't tracked, or sent to any server; just encoded directly in your browser!)");
						console.log(err.message, err.stack);
					}
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as OGG (Opus format, libopusjs)";
				exportBtn.onclick = async function() {
					function floatTo16BitPCM(float32Array, channels) {
						const len = float32Array[0].length;
						const buffer = new Int16Array(len * channels);
						let s = 0;
						if (channels === 1) {
							for (let i = 0; i < len; i++) {
								s = float32Array[0][i];
								buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						} else {
							for (let i = 0, j = 0; i < len; i++, j+=channels) {
								s = float32Array[0][i];
								buffer[j] = s < 0 ? s * 0x8000 : s * 0x7fff;
								s = float32Array[1][i];
								buffer[j + 1] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						}
						return buffer;
					}
// Simple Ogg-Opus muxer (browser compatible) (I DID NOT WRITE ANY OF THE OGG MUXING LOGIC!!! GPT-5.0 Non-mini/Mini, and Claude Sonnet 4.5 DID THIS!)
// - Expects: packets = Array<Uint8Array> (raw Opus packets, in order)
// - Options:
//		sampleRate: number (default 48000)
//		channels: number (default 2)
//		serial: 32-bit stream serial (random by default)
//		pageSizeLimit: approx max body size per page (defaults chosen for decent packing)
//		getPacketSamples(packet): function(Uint8Array) -> number (samples per channel)
//			 If not provided, default assumes frames of 20ms (960 samples @48kHz) and
//			 parses simple TOC frame-count rules (good if your encoder uses 20ms frames).
// Returns: Blob (type 'audio/ogg')
//
// References:
//	- Ogg framing: RFC 3533 / xiph.org docs.
//	- Opus in Ogg: RFC 7845.
//	- Opus packet TOC: RFC 6716 (used for a basic frame-count calculation).
//
// This is intentionally minimal; production muxers do additional checks and
// better packing heuristics.

// Full browser-ready Ogg-Opus muxer (minimal, RFC-compliant) — corrected paging logic
function muxOpusPacketsToOgg(packets, opts = {}) {
	const {
		sampleRate = 48000,
		channels = 2,
		serial = (Math.random() * 0xffffffff) >>> 0,
		pageSizeLimit = 65000,
		getPacketSamples = defaultGetPacketSamples(20, sampleRate),
		vendor = "libopusjs-muxer",
		debug = true
	} = opts;

	// --- Helper functions (unchanged) ---
	const concatUint8 = (chunks) => {
		const total = chunks.reduce((sum, c) => sum + c.length, 0);
		const out = new Uint8Array(total);
		let offset = 0;
		for (const c of chunks) { out.set(c, offset); offset += c.length; }
		return out;
	};

	function write32LE(buf, offset, value) {
		const dv = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
		dv.setUint32(offset, value >>> 0, true);
	}
	function write64LE(buf, offset, value) {
		const dv = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
		const v = BigInt(value);
		dv.setUint32(offset, Number(v & 0xffffffffn), true);
		dv.setUint32(offset + 4, Number((v >> 32n) & 0xffffffffn), true);
	}

	// CRC32 table (unchanged)
	const CRC32 = (() => {
		const table = new Uint32Array(256);
		for (let i = 0; i < 256; i++) {
			let r = i;
			for (let j = 0; j < 8; j++) {
				r = (r & 1) ? (0xEDB88320 ^ (r >>> 1)) : (r >>> 1);
			}
			table[i] = r >>> 0;
		}
		return (buf) => {
			let crc = 0xffffffff;
			for (let i = 0; i < buf.length; i++) crc = (crc >>> 8) ^ table[(crc ^ buf[i]) & 0xff];
			return (crc ^ 0xffffffff) >>> 0;
		};
	})();

	// OpusHead (unchanged)
	function createOpusHead() {
		const buf = new Uint8Array(19);
		buf.set(new TextEncoder().encode("OpusHead"), 0);
		buf[8] = 1;			  // version
		buf[9] = channels;	   // channel count
		buf[10] = 0x38; buf[11] = 0x01; // pre-skip 312 samples
		buf[12] = sampleRate & 0xff; buf[13] = (sampleRate >> 8) & 0xff;
		buf[14] = (sampleRate >> 16) & 0xff; buf[15] = (sampleRate >> 24) & 0xff;
		buf[16] = buf[17] = 0;   // gain
		buf[18] = 0;			 // mapping family
		return buf;
	}

	// OpusTags (unchanged)
	function createOpusTags(vendorStr = vendor, comments = {}) {
		const vendorBytes = new TextEncoder().encode(vendorStr);
		const userComments = Object.entries(comments).map(([k,v]) => `${k}=${v}`);
		const commentBytes = userComments.map(s => new TextEncoder().encode(s));

		let totalLen = 8 + 4 + vendorBytes.length + 4;
		for (const b of commentBytes) totalLen += 4 + b.length;

		const buf = new Uint8Array(totalLen);
		const dv = new DataView(buf.buffer);
		let offset = 0;
		buf.set(new TextEncoder().encode("OpusTags"), offset); offset += 8;
		dv.setUint32(offset, vendorBytes.length, true); offset += 4;
		buf.set(vendorBytes, offset); offset += vendorBytes.length;
		dv.setUint32(offset, commentBytes.length, true); offset += 4;
		for (const b of commentBytes) { dv.setUint32(offset, b.length, true); offset += 4; buf.set(b, offset); offset += b.length; }
		return buf;
	}

	// --- New robust page builder ---
	const pages = [];
	let pageSeq = 0;
	let granule = 0n; // absolute samples (per-channel) up to last completed packet
	const MAX_SEGMENTS = 255;

	function buildAndPushPage(segmentTable, bodyParts, pageStartedWithContinuation, isBOS, isEOS) {
		const header = new Uint8Array(27 + segmentTable.length);
		header.set(new TextEncoder().encode("OggS"), 0);
		header[4] = 0; // version
		let flags = 0x00;
		if (pageStartedWithContinuation) flags |= 0x01;
		if (isBOS) flags |= 0x02;
		if (isEOS) flags |= 0x04;
		header[5] = flags;

		// granule must be set before CRC calculation; pass the current granule (already updated for completed packets)
		write64LE(header, 6, granule);

		write32LE(header, 14, serial);
		write32LE(header, 18, pageSeq++);
		write32LE(header, 22, 0); // CRC placeholder

		header[26] = segmentTable.length;
		header.set(segmentTable, 27);

		const pageBody = concatUint8(bodyParts);
		// compute CRC over header(with CRC=0) + body, then write CRC into header and push
		const fullPage = concatUint8([header, pageBody]);
		const crc = CRC32(fullPage);
		write32LE(header, 22, crc);

		pages.push(concatUint8([header, pageBody]));
	}

	// --- Write BOS pages (OpusHead + OpusTags) ---
	buildAndPushPage(
		new Uint8Array([createOpusHead().length]), // temporary single-segment trick doesn't matter here because we put OpusHead as a single packet below
		[createOpusHead()],
		false, /*continued*/ true, /*BOS*/ false /*EOS*/
	);

	buildAndPushPage(
		(function(){ // OpusTags may be larger than 255 segments but almost never; treat it as one full packet normally
			const t = createOpusTags(vendor, {});
			const segs = [];
			let off = 0;
			while (off < t.length) { const take = Math.min(255, t.length - off); segs.push(take); off += take; }
			return new Uint8Array(segs);
		})(),
		[createOpusTags(vendor, {})],
		false, /*continued*/ false /*BOS*/ , false /*EOS*/
	);

	// --- Audio packet to pages logic (robust) ---
	let pktIndex = 0;
	let pktOffset = 0; // byte offset inside current packet (for continuation)
	while (pktIndex < packets.length) {
		// start a new page
		const segs = [];
		const bodyParts = [];
		let bodySize = 0;
		const pageStartedWithContinuation = pktOffset !== 0;
		let segmentsCount = 0;

		// We'll remember whether any packet *completed* on this page so we can update granule accordingly.
		// granule already contains samples up to the last completed packet before this page.
		// When a packet completes on this page we add its samples to granule immediately so final granule reflects last-complete.
		let anyCompletionOnThisPage = false;

		while (segmentsCount < MAX_SEGMENTS && bodySize < pageSizeLimit && pktIndex < packets.length) {
			const pkt = packets[pktIndex];
			const remaining = pkt.length - pktOffset;
			const toTake = Math.min(255, remaining);

			// If adding this segment would exceed the pageSizeLimit, break.
			if (bodySize + toTake > pageSizeLimit) {
				// If bodySize is zero and toTake > pageSizeLimit, we still must put at least one segment (even if > limit) — but toTake <= 255 so okay.
				break;
			}

			// append segment and body chunk
			segs.push(toTake);
			bodyParts.push(pkt.subarray(pktOffset, pktOffset + toTake));
			bodySize += toTake;
			segmentsCount += 1;
			pktOffset += toTake;

			if (pktOffset === pkt.length) {
				// packet completed on this page — increment granule by its sample count
				const samples = BigInt(getPacketSamples(pkt));
				granule += samples;
				anyCompletionOnThisPage = true;

				// move to next packet
				pktIndex += 1;
				pktOffset = 0;
			} else {
				// packet still continues to next page
				// we must stop if segmentsCount reached 255 (outer loop checks), otherwise the outer while will continue
				// but we must break if we've filled the page (bodySize >= pageSizeLimit) — outer loop checks
			}
		}
		// Decide EOS: only true for the final page after we've processed all packets (and no remaining partial)
		const isEOS = (pktIndex >= packets.length && pktOffset === 0);
		// Special rule: if this page contains NO completed packets, granule must be set to the previous granule value (which it already is)
		// build segment table Uint8Array
		const segmentTable = new Uint8Array(segs);
		// push page
		buildAndPushPage(segmentTable, bodyParts, pageStartedWithContinuation, false, isEOS);
		// Continue; the loop will start next page with pktOffset possibly non-zero (continuation)
	}
	if (debug) console.log(`Created ${pages.length} pages, final granule: ${granule}`);
	return new Blob(pages, { type: "audio/ogg" });
}
// --- Default packet sample counter ---
function defaultGetPacketSamples(frameMs = 20, sampleRate = 48000) {
	const frameSamples = Math.round(sampleRate * (frameMs / 1000));
	return function(packet) {
		if (!packet || packet.length === 0) return 0;
		const toc = packet[0];
		const code = toc & 0x03;
		let frames = 1;
		if (code === 1 || code === 2) frames = 2;
		else if (code === 3 && packet.length >= 2) frames = packet[1] & 0x3f || 1;
		return frames * frameSamples;
	};
}
					try {
						const vbr = Number(prompt("How high can the bitrate of the audio be? (6.0 = worst quality, big differences, low sizes; 512.0 = best quality, nearly-neglible differences, higher sizes; 256.0 = balanced quality, minimal differences, medium sizes)") ?? 256.0) ?? 256.0;
						const voiceOpt = confirm("Should the audio encoder optimize for voices in the audio?");
						let blob;
						const split = exporters.length !== 2 && !!confirm("Should the audio be split into two separate channels?");

						const times = Number(prompt("How many times would the audio be re-encoded?") || 1) || 1;

						for (let i = 0; i < times; i++) {
							let buffer = i === 0 ? exporters.map(exp => timelineBeginAudio ? exp.audioData.subarray(timelineBeginAudio, timelineEndAudio) : exp.audioData) : await audioContext.decodeAudioData(await blob.arrayBuffer());
							let altRate = buffer.sampleRate;
							if (i > 0) {
								if (buffer.numberOfChannels === 2) buffer = [buffer.getChannelData(0), buffer.getChannelData(1)]; else buffer = [buffer.getChannelData(0)];
							}
// Rest of encoding logic is implemented by GPT-5.0 Mini.
		// Prepare channels
		const bufferF = split || buffer.length === 2 ? [buffer[0], buffer[1] || buffer[0]] : [buffer[0]];
		const channels = bufferF.length;

							const sampleRate = altRate || exporters[0].sampleRate; // Except this line, I added this.

		// Create encoder
		const encoder = new Encoder(channels, sampleRate, vbr, 20, voiceOpt);
		const arr = [];

		// Frame-slice
		const frameSize = sampleRate * 20 / 1000; // 20ms @ 48kHz | Except this line, this altered modified by me.
		const totalSamples = bufferF[0].length;

		for (let pos = 0; pos + frameSize <= totalSamples; pos += frameSize) {
			const frame = bufferF.map(ch => ch.subarray(pos, pos + frameSize));
			const pcm = floatTo16BitPCM(frame, channels);
			encoder.input(pcm);

			// Drain packets
			let pkt;
			while ((pkt = encoder.output()) != null) {
									arr.push(pkt);
								}
							}

							console.log("Packets:", arr);

							// Mux into OGG
							blob = muxOpusPacketsToOgg(arr, {
								sampleRate,
								channels
							});
							encoder.destroy();
						}

						const link = document.createElement("a");
						link.download = "exportedAudio.ogg";
						link.href = URL.createObjectURL(blob);
						link.click();
						link.remove();
					} catch (err) {
						alert("It seems like the OGG Opus codec is supported, but not yet available. READ BELOW:\n\nA network is required to export your audio into the OGG format. The encoder itself is stored in an online module server (UNPKG.com), then loaded into this audio editor. (This means your audio track or other invaluable information isn't tracked, or sent to any server; just encoded directly in your browser!)");
						console.log(err.message, err.stack);
					}
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as FLAC (libflac.js)";
				exportBtn.onclick = async function() { // This function was written entirely by Claude Sonnet 4.5. I made some modifications to the original code.
					try {
						// Setup for collecting encoded data
						const encBuffer = [];

						// Callback to receive encoded FLAC data
						function write_callback_fn(buffer) {
							// Copy the buffer immediately (same issue as with OGG Vorbis!)
							const copy = new Uint8Array(buffer);
							encBuffer.push(copy);
						}

						// Create encoder
						const CHANNELS = exporters.length;
						const SAMPLERATE = exporters[0].sampleRate;
						const BPS = confirm("Would you like the audio to be encoded in 16-bit? If not, it'll be encoded in 24-bit.") ? 16 : 24; // 24-bit encoding
						const COMPRESSION = Number(prompt("What is the quality of the audio? (In accurate terms, how aggressive is the lossless compression? 0 = fastest compression, largest file, 8 = slower compression, smaller file, 5 = balanced compression, balanced file)") ?? 5);
						const VERIFY = false;
						const BLOCK_SIZE = 0; // 0 = let encoder decide

						const junkMode = (BPS !== 16 || confirm("Do you want your FLAC to not have any garbage data?")) ? 1 : 0;

						const flac_encoder = Flac.create_libflac_encoder(
							SAMPLERATE,
							CHANNELS,
							BPS,
							COMPRESSION,
							(timelineBeginAudio ? (timelineEndAudio - timelineBeginAudio) : exporters[0].audioData.length) * (2 - junkMode), // total_samples (0 = unknown)
							VERIFY,
							BLOCK_SIZE
						);

						// Initialize encoder with write callback
						const initStatus = Flac.init_encoder_stream(
							flac_encoder,
							write_callback_fn
						);

						if (initStatus !== 0) {
							throw new Error("FLAC encoder initialization failed");
						}

						// Convert Float32 to 24-bit integers (packed as Int32Array)
						const audioData = exporters.map(i => timelineBeginAudio ? 
							i.audioData.subarray(timelineBeginAudio, timelineEndAudio) :
							i.audioData);

						let encodedStatus = false;

						if (BPS === 24) {
							const int24Buffer = new Int32Array(audioData[0].length * audioData.length);
							if (audioData.length === 2) {
								const aa = audioData[0];
								const ab = audioData[1];
								for (let i = 0, j = 0; i < int24Buffer.length; i += 2, j++) {
									int24Buffer[i] = (aa[j] * 8388607) | 0;
									int24Buffer[i + 1] = (ab[j] * 8388607) | 0;
								}
							} else {
								const aa = audioData[0];
								for (let i = 0; i < aa.length; i++) {
									int24Buffer[i] = (aa[i] * 8388607) | 0;
								}
							}

							encodedStatus = Flac.FLAC__stream_encoder_process_interleaved(
								flac_encoder,
								int24Buffer,
								audioData[0].length
							);
						} else if (BPS === 16) {
							let int16Buffer = new Int16Array();
							const len = audioData[0].length * audioData.length * 2;
							if (!junkMode) int16Buffer = new Int16Array(len * 2); else int16Buffer = new Int32Array(audioData[0].length * audioData.length);
							if (junkMode) {
								if (audioData.length === 2) {
									const aa = audioData[0];
									const ab = audioData[1];
									for (let i = 0, j = 0; i < int16Buffer.length; i += 2, j++) {
										int16Buffer[i] = (aa[j] * 32767) | 0;
										int16Buffer[i + 1] = (ab[j] * 32767) | 0;
									}
								} else {
									const aa = audioData[0];
									for (let i = 0; i < aa.length; i++) {
										int16Buffer[i] = (aa[i] * 32767) | 0;
									}
								}
							} else {
								if (audioData.length === 2) {
									const aa = audioData[0];
									const ab = audioData[1];
									for (let i = 0, j = 0; i < len; i += 4, j++) {
										int16Buffer[i] = (aa[j] * 32767) | 0;
										int16Buffer[i + 1] = (ab[j] * 32767) | 0;
										int16Buffer[i + 2] = int16Buffer[i];
										int16Buffer[i + 3] = int16Buffer[i + 1];
									}
								} else {
									const aa = audioData[0];
									for (let i = 0, j = 0; i < aa.length; i++, j += 2) {
										int16Buffer[j] = (aa[i] * 32767) | 0;
										int16Buffer[j + 1] = int16Buffer[j];
									}
								}
							}

							encodedStatus = Flac.FLAC__stream_encoder_process_interleaved(
								flac_encoder,
								int16Buffer,
								audioData[0].length
							);
						}

						if (!encodedStatus) {
							throw new Error("FLAC encoding failed");
						}

						// Finish encoding
						const finishStatus = Flac.FLAC__stream_encoder_finish(flac_encoder);

						if (!finishStatus) {
							throw new Error("FLAC finalization failed");
						}

						// Clean up
						Flac.FLAC__stream_encoder_delete(flac_encoder);

						// Combine all encoded chunks
						const totalLength = encBuffer.reduce((sum, chunk) => sum + chunk.length, 0);
						const flacData = new Uint8Array(totalLength);
						let offset = 0;
						for (const chunk of encBuffer) {
							flacData.set(chunk, offset);
							offset += chunk.length;
						}

						// Download
						const blob = new Blob([flacData], { type: "audio/flac" });
						const link = document.createElement("a");
						link.download = "exportedAudio.flac";
						link.href = URL.createObjectURL(blob);
						link.click();
						link.remove();
					} catch (err) {
						alert("The FLAC encoding failed: " + err.message);
						console.error(err);
					}
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as LSAC (LoSsy Audio Codec)";
				exportBtn.onclick = function() {
					const blob = encodeLSAC(exporters[0].audioData, exporters[0].sampleRate);

					const link = document.createElement("a");
					link.download = "exportedAudio.lsac";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as FBAC (Frame-Based Audio Codec)";
				exportBtn.onclick = function() {
					const blob = encodeFBAC(exporters[0].audioData, exporters[0].sampleRate);

					const link = document.createElement("a");
					link.download = "exportedAudio.fbac";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				window.onscroll = function() {
					apply.style.marginLeft = window.scrollX + "px";
					opt.style.marginLeft = apply.style.marginLeft;
					params.style.marginLeft = apply.style.marginLeft;
					selectLabel.style.marginLeft = apply.style.marginLeft;
					selectLabel.style.wordWrap = "keep-all";
					selectLabel.style.whiteSpace = "nowrap";
					if (window.scrollX > window.innerWidth - selectLabel.getBoundingClientRect().width) selectBox.style.marginLeft = apply.style.marginLeft; else selectBox.style.marginLeft = "";
					if (sampleSkip === 1) {
						count++;
						if (count < 4) return;
						count = 0;
						let data2 = ["M 0,100 L 0,100"];
						let xn = window.scrollX;
						x.setAttribute("width", window.innerWidth);
						x.style.marginLeft = (xn - xOff) + "px";
						const len = Math.min(xn - xOff + window.innerWidth, yu), y = exp[0].audioData;
						let prev = 0, val = y[0];
						let ep = 0.004;
						for (let i = xn, j = 0; i < len; i++, j++) {
							if (Math.abs(prev - val) >= ep) {
								data2.push("L " + j + "," + Math.round(100 + val * 100));
								prev = val;
							}
							val = y[i];
						}
						data2.push("L " + (len / sampleSkip) + ",100");
						n.setAttribute("d", data2.join(" "));
						if (n2) {
							data2 = ["M 0,100 L 0,100"];
							const y = exp[1].audioData;
							let prev = 0, val = y[0];
							for (let i = xn, j = 0; i < len; i++, j++) {
								if (Math.abs(prev - val) >= ep) {
									data2.push("L " + j + "," + Math.round(100 + val * 100));
									prev = val;
								}
								val = y[i];
							}
							data2.push("L " + (len / sampleSkip) + ",100");
							n2.setAttribute("d", data2.join(" "));
						}
					}
				}
				effects["trim"] = function(ex) {
					if (timelineBeginAudio) ex.audioData = ex.audioData.subarray(timelineBeginAudio, timelineEndAudio); else alert("You have not selected any portion of the audio yet.");
				}
				ed = v;
				div = x;
			}

			effectsList.push([
				"Trim",
				"Removes all of the contents that is not selected by the blue selection box.",
				'',
				0,
				"trim",
				[]
			]);

			audioInput.oninput = async function(eve) {
				if (eve.target.files.length === 0) return;
				let firstFile = eve.target.files[0];
				let secondFile = eve.target.files[1];
				let isCorrect;
				function swapFiles() {
					const temp = secondFile;
					secondFile = firstFile;
					firstFile = temp;
				}
				if (secondFile) {
					isCorrect = confirm("It seems like you selected two audio files. Is this correct?");
					if (isCorrect) alert("*This editor cannot interpret the second file as raw audio because the maintainer of this editor has not implemented this feature... yet." + (whichInterpret ? " Not that the audio won't be decoded." : ""));
					if (!confirm("Which file is the one you want to edit?\nOK = " + firstFile.name.trim() + "\nCancel (or X) = " + secondFile.name.trim())) {
						swapFiles();
					}
				}
				if (!whichInterpret && (firstFile.name.endsWith(".lsac") || firstFile.name.endsWith(".fbac"))) {
					try {
						exporters = null;
						if (ed) {
							ed.innerHTML = "";
							ed.remove();
							ed = null;
						}
						data = null;
						sampleData = null;
						sampleSkip = 480;
						let result = 0;
						if (firstFile.name.endsWith(".lsac")) result = await decodeLSAC(firstFile); else result = await decodeFBAC(firstFile);
						sharedBuffer = audioContext.createBuffer(1, result.samples.length, result.sampleRate);
						const len = result.samples.length;
						const bufferData = sharedBuffer.getChannelData(0);
						const samples = result.samples;
						for (let i = 0; i < len; i++) {
							bufferData[i] = samples[i];
						}
						exporters = [new AudioExporter(result.samples, result.sampleRate, 1, 32)];
						loadDiv(exporters[0]);
					} catch (err) {
						alert("The audio could not be properly loaded! Due to unhelpful strip-aways from viewing metadata, we cannot provide much info on what exactly failed.");
						console.log(err.message + err.stack);
					}
				} else {
					const fileReader = new FileReader();
					fileReader.onload = async function(event) {
						try {
							exporters = null;
							if (ed) {
								ed.innerHTML = "";
								ed.remove();
								ed = null;
							}
							data = null;
							sampleData = null;
							sampleSkip = 480;
							if (whichInterpret) {
								const data = event.target.result;
								const type = Number(prompt("How will the audio be interpreted? (0 = integers, 1 = floats)"));
								const bits = Math.max(prompt("What is the bits per sample of the audio?") >> 3, 1);
								sharedBuffer = audioContext.createBuffer(1, data.byteLength / bits, prompt("What is the samplerate of the audio?") || 48000);
								const channel = sharedBuffer.getChannelData(0);
								const len = sharedBuffer.length;
								const buffer = new Uint8Array(data);
								if (type === 0) {
									if (bits === 1) {
										const bufferInt = new Int8Array(data);
										for (let i = 0; i < len; i++) {
											channel[i] = bufferInt[i] / 0x80;
										}
									} else if (bits === 2) {
										for (let i = 0, j = 0; i < len; i += bits, j++) {
											channel[j] = ((buffer[i + 1] << 8) | buffer[i]) / 0x8000 - 0.5;
										}
									} else if (bits === 3) {
										for (let i = 0, j = 0; i < len; i += bits, j++) {
											channel[j] = ((buffer[i + 2] << 16) | (buffer[i + 1] << 8) | buffer[i]) / 0x800000 - 0.5;
										}
									} else if (bits === 4) {
										for (let i = 0, j = 0; i < len; i += bits, j++) {
											channel[j] = ((buffer[i + 3] << 24) | (buffer[i + 2] << 16) | (buffer[i + 1] << 8) | buffer[i]) / 0x80000000 - 0.5;
										}
									}
								} else if (type === 1) {
									const s = Math.sign;
									if (bits === 4) {
										const f = new Float32Array(data.slice(0, data.byteLength >> 2 << 2));
										const lenF = f.length;
										let x;
										for (let i = 0; i < lenF; i++) {
											x = f[i];
											channel[i] = (x === Infinity ? 1 : (x === -Infinity ? -1 : (isNaN(x) ? 0 : x))) || 0;
											channel[i] = channel[i] > 1 ? 1 : (channel[i] < -1 ? -1 : channel[i]);
										}
									} else if (bits === 8) {
										const f = new Float64Array(data.slice(0, data.byteLength >> 3 << 3));
										const lenF = f.length;
										let x;
										for (let i = 0; i < lenF; i++) {
											x = f[i];
											channel[i] = (x === Infinity ? 1 : (x === -Infinity ? -1 : (isNaN(x) ? 0 : x))) || 0;
											channel[i] = channel[i] > 1 ? 1 : (channel[i] < -1 ? -1 : channel[i]);
										}
									}
								}
								exporters = [new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32)];
								loadDiv(exporters);
								return;
							}
							sharedBuffer = await audioContext.decodeAudioData(event.target.result);
							if (isCorrect) {
								alert("The first audio file was decoded.");
								const fileReader2 = new FileReader();
								let secondSharedBuffer;
								await new Promise(function(resolve) {
									try {
										fileReader2.onload = async function(eve) {
											try {
												secondSharedBuffer = await audioContext.decodeAudioData(eve.target.result);
											} catch {
												alert("Looks like the second audio file has failed to be decoded! However, you can still edit the main audio.");
											}
											if (secondSharedBuffer && confirm("Would you like to layer both audio files together?")) {
												let inway = Number(prompt("Alright! Which way should the audio editor layer the audio files together? (0 = audioFile1 + audioFile2, 1 = audioFile1 - audioFile2, 2 = audioFile2 - audioFile1") || 0);
												if (sharedBuffer.sampleRate === secondSharedBuffer.sampleRate && sharedBuffer.numberOfChannels === secondSharedBuffer.numberOfChannels) {
													let len;
													if (sharedBuffer.length < secondSharedBuffer.length) {
														len = secondSharedBuffer.length;
														const temp = secondSharedBuffer;
														secondSharedBuffer = sharedBuffer;
														sharedBuffer = temp;
													} else len = sharedBuffer.length;
													if (inway === 0) {
														for (let i = 0; i < secondSharedBuffer.numberOfChannels; i++) {
															const pointer1 = sharedBuffer.getChannelData(i);
															const pointer2 = secondSharedBuffer.getChannelData(i);
															for (let j = 0; j < len; j++) {
																pointer1[j] += pointer2[j];
															}
														}
													} else if (inway === 1 || inway === 2 || inway === 3 || inway === 4) {
														if (inway === 3 || inway === 4) {
															for (let i = 0; i < secondSharedBuffer.numberOfChannels; i++) {
																const pointer = (inway === 3 ? sharedBuffer.getChannelData(i) : secondSharedBuffer.getChannelData(i));
																for (let j = 0; j < len; j++) {
																	pointer[j] *= 0.5;
																}
															}
															inway -= 2;
														}
														for (let i = 0; i < secondSharedBuffer.numberOfChannels; i++) {
															let pointer1;
															let pointer2;
															if (inway === 1) {
																pointer1 = sharedBuffer.getChannelData(i);
																pointer2 = secondSharedBuffer.getChannelData(i);
															} else {
																pointer2 = sharedBuffer.getChannelData(i);
																pointer1 = secondSharedBuffer.getChannelData(i);
															}
															for (let j = 0; j < len; j++) {
																pointer1[j] -= pointer2[j];
															}
														}
													}
												} else alert("Looks like the audio files' metadata doesn't exactly match each other well! You can still edit the main audio, though.");
											}
											resolve();
										}
										fileReader2.readAsArrayBuffer(secondFile);
									} catch {
										alert("Looks like the second audio file has failed to be decoded! However, you can still edit the main audio.");
										resolve();
									}
								});
							}
							const channelNum = Math.max(1, Math.min(+prompt("Which channel should be imported for editing? Pick a channel from 1 to " + sharedBuffer.numberOfChannels + ". (Editing multiple channels at once isn't an option due to the maintainer's preferred simplicity.)") || 1, sharedBuffer.numberOfChannels)) - 1;
							const channel = sharedBuffer.getChannelData(channelNum);
							let isProcessed = false;
							if (sharedBuffer.numberOfChannels === 2) {
								if (confirm("Should the current channel be subtracted by another? (If you want to only edit the audio, just press Cancel)")) {
									const channelOtherNum = sharedBuffer.numberOfChannels - channelNum - 1;
									const len = channel.length;
									const channelOther = sharedBuffer.getChannelData(channelOtherNum);
									const choice = Number(prompt("Okay then! Which formula do you want to choose? (0 = channel" + channelNum + " - otherChannel | 1 = channel" + channelNum + " * 2 - otherChannel | 2 = channel" + channelNum + " - (otherChannel - channel" + channelNum + ") / 2 | 3 = 2 but otherChannel" + channelNum + " * 2 | 4 = channel" + channelNum + " + otherChannel)"));
									if (choice === 0) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i];
										}
									} else if (choice === 1) {
										for (let i = 0; i < len; i++) {
											channel[i] = channelOther[i] - channel[i];
										}
									} else if (choice === 2) {
										for (let i = 0; i < len; i++) {
											channel[i] -= Math.abs(channelOther[i] - channel[i]);
										}
									} else if (choice === 3) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i] * 2 - channel[i];
										}
									} else if (choice === 3.5) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i] - channel[i] * 2;
										}
									} else if (choice === 4) {
										for (let i = 0; i < len; i++) {
											channel[i] = (channel[i] + channelOther[i]) * 0.5;
										}
									}
									isProcessed = true;
								}
							}
							const stereo = sharedBuffer.numberOfChannels === 2 && !isProcessed && confirm("Do you want the final audio to be stereo?");
							if (sharedBuffer.numberOfChannels > 1 && !stereo) { // Normalize playback, since only one channel is being loaded. If other channels are playing while one is selected, it can suddenly sound "mono" if an effect is applied, which confuses the user
								for (let i = 0; i < sharedBuffer.numberOfChannels; i++) {
									if (i === channelNum) continue;
									const silentBuffer = sharedBuffer.getChannelData(i);
									if (silentBuffer) silentBuffer.set(channel);
								}
							}
							if (stereo) exporters = [new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32), new AudioExporter(sharedBuffer.getChannelData(1 - channelNum), sharedBuffer.sampleRate, 1, 32)];
							else exporters = [new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32)];
							loadDiv(exporters);
						} catch (err) {
							alert("The audio could not be properly loaded! We couldn't gather any info on what exactly failed, so the best we can say is: try selecting another audio file, or using another browser.");
							console.log(err.message + err.stack);
						}
					}
					fileReader.readAsArrayBuffer(firstFile);
				}
			}
			loadBlank.onclick = function() {
				exporters = null;
				if (ed) {
					ed.innerHTML = "";
					ed.remove();
					ed = null;
				}
				data = null;
				sampleData = null;
				sampleSkip = 480;
				sharedBuffer = audioContext.createBuffer(1 + confirm("Will the blank audio be mono (1 channel, select \"Cancel\") or stereo (2 channels, select \"OK\" or \"Yes\")?"), (Math.round(Math.abs(Number(prompt("How long is the blank audio (in seconds)?")))) || 1) * 48000, 48000);
				const stereo = sharedBuffer.numberOfChannels === 2;
				if (stereo) exporters = [new AudioExporter(sharedBuffer.getChannelData(0), sharedBuffer.sampleRate, 1, 32), new AudioExporter(sharedBuffer.getChannelData(1), sharedBuffer.sampleRate, 1, 32)];
				else exporters = [new AudioExporter(sharedBuffer.getChannelData(0), sharedBuffer.sampleRate, 1, 32)];
				loadDiv(exporters, true);
			}
			tick();
		</script>
	</body>
</html>
