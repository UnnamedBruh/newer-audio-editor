<!DOCTYPE html>
<html lang="en">
	<head>
		<style>
			body {
				background-color: black;
				color: white;
				font-family: Arial, sans-serif;
				min-width: 100vw;
			}
			div {
				border-radius: 8px;
				background-color: rgb(30, 30, 30);
			}
		</style>
	</head>
	<body>
		<script src="audioEditor.js"></script>
		<script src="audioExporter.js"></script>
		<script src="audioEffects.js"></script>
		<script src="audioLSAC.js"></script>
		<script src="audioFBAC.js"></script>
		<script src="lame.min.js"></script>
		<script src="audioEncoders.unpkg.js"></script>
		<script src="flacjs/libflac.min.js"></script>
		Volume (<a id="la" style="width: 100px">100</a>%): <input type="range" id="vol" min="0" max="10" step="0.01" value="1" style="width: 100%"><br>
		Volume Multiplier (<a id="la2" style="width: 100px">100</a>%): <input type="range" id="vol2" min="0" max="10" step="0.01" value="1" style="width: 100%"><br>
		<a id="selectlabel">Selecting A Certain Region?</a> <input type="checkbox" id="select">
		<h1>Audio Editor</h1>
		<p>I've been trying to think of ways to refine it, and I've also been watching YouTube videos, which is the reason why I barely worked on anything. But finally, the audio editor is here!</p>
		Current Audio File: <input type="file" id="aud" accept=".wav, .mp3, .ogg, .flac, .aac, .weba, .m4v, .m4a, .mp4, .3gp, .3g2, .webm, .lsac, .fbac" multiple><br>
		<button id="which">Decode The Audio File</button>
		<script>
			const audioContext = new (window.AudioContext || window.webkitAudioContext)();
			const audioInput = document.getElementById("aud"), volume = document.getElementById("vol"), label = document.getElementById("la"), volume2 = document.getElementById("vol2"), label2 = document.getElementById("la2"), selectBox = document.getElementById("select"), selectLabel = document.getElementById("selectlabel");
			let exporters = null;
			let sharedBuffer = null, src = null, whenPlayed = 0, playing = false, timeline = null, timelineBegin = null, timelineEnd = null, highlight = null, timelineBeginNum = 0, timelineEndNum = 0, timelineEndNumCache = 0, timelineBeginAudio = 0, timelineEndAudio = 0, timelineIter = -1, isPressingShift = false, startAt = 0, bbb = 0, ed = null, div = null, data = null, skipSample = 480, volumeWarning = true, prevIntervalID = null, xOff, skipSampleUnround = 480;
			let gainNode = audioContext.createGain();
			const interpretFiles = document.getElementById("which");
			let whichInterpret = false;
			selectBox.oninput = function() {
				isPressingShift = selectBox.checked;
			}
			interpretFiles.onclick = function() {
				whichInterpret = !whichInterpret;
				interpretFiles.textContent = whichInterpret ? "Treat File Data As Audio" : "Decode The Audio File";
				audioInput.accept = whichInterpret ? "*" : ".wav, .mp3, .ogg, .flac, .aac, .weba, .m4v, .m4a, .mp4, .3gp, .3g2, .webm, .lsac, .fbac";
			}
			gainNode.connect(audioContext.destination);
			gainNode.gain.value = 1;
			volume.oninput = function() {
				if (volumeWarning) {
					volumeWarning = false;
					alert("Moving the knob to the right can cause incredibly loud results! Please use the volume sliders responsibly and ethically, as these are very experimental features.");
					volume.value = 1;
				}
				let x = +volume.value;
				if (x > 0.9 && x < 1.1) x = volume.value = 1;
				label.textContent = Math.round(x * 100);
				label.textContent = label.textContent;
				gainNode.gain.value = x * +volume2.value;
				if (x >= +volume.max / 1.1) {
					volume.max *= 10;
					volume.disabled = true;
					document.onmouseup = function() {
						volume.disabled = false;
						document.onmouseup = null;
					}
				}
			}
			volume2.oninput = function() {
				if (volumeWarning) {
					volumeWarning = false;
					alert("Moving the knob to the right can cause incredibly loud results! Please use the volume sliders responsibly and ethically, as these are very experimental features.");
					volume.value = 1;
				}
				let x = +volume2.value;
				if (x > 0.9 && x < 1.1) x = volume2.value = 1;
				label2.textContent = Math.round(x * 100);
				label2.textContent = label2.textContent;
				gainNode.gain.value = x * +volume.value;
				if (x >= +volume2.max / 1.1) {
					volume2.max *= 10;
					volume2.disabled = true;
					document.body.onmouseup = function() {
						volume2.disabled = false;
						document.body.onmouseup = null;
					}
				}
			}
			function tick() {
				if (timeline && playing) {
					let x = (Date.now() - whenPlayed) / 1000;
					if (sampleSkip === 1) {
						timeline.setAttribute("x", x * sharedBuffer.sampleRate / sampleSkip + bbb - window.pageXOffset);
					} else {
						timeline.setAttribute("x", x * sharedBuffer.sampleRate / sampleSkip + bbb);
					}
					if (timelineEndNum !== 0 && x > timelineEndNumCache) {
						playing = false;
						src.stop();
					}
				}
				requestAnimationFrame(() => tick());
			}
			function playSound() {
				if (!sharedBuffer) return;
				if (src) {
					src.onended = function() {};
					if (playing) {
						try {
							src.stop();
						} catch {};
					}
				}
				src = audioContext.createBufferSource();
				src.buffer = sharedBuffer;
				src.connect(gainNode);
				startAt += timelineBeginNum / div.clientWidth * sharedBuffer.duration;
				src.start(0, startAt);
				whenPlayed = Date.now() - startAt * 1000;
				playing = true;
				if (timeline) timeline.setAttribute("fill", "red");
				src.onended = function() {
					playing = false;
					timeline.setAttribute("fill", "none");
				}
			}
			function generateWaveform(exp) {
				let data2 = ["M 0,100 L 0,100"];
				const len = exp.audioData.length, y = exp.audioData;
				let prev = 0, val;
				let ep = 0.004;
				val = y[0];
				let b = 0;
				for (let i = 0, j = 0; i < len; i = b, j++) {
					b = i + sampleSkip;
					if (Math.abs(prev - val) >= ep) {
						data2.push("L " + j + "," + Math.round(100 + val * 100));
						val = y[b] || 0;
					}
					prev = y[i];
				}
				data2.push("L " + (len / sampleSkip) + ",100");
				return data2.join(" ");
			}
			function loadDiv(exp) {
				if (prevIntervalID !== undefined) clearInterval(prevIntervalID);
				const v = document.createElement("div");
				const x = document.createElementNS("http://www.w3.org/2000/svg", "svg");
				document.body.appendChild(v);
				v.appendChild(x);
				x.setAttribute("width", exp[0].audioData.length / sampleSkip);
				v.style.width = (exp[0].audioData.length / sampleSkip) + "px";
				x.setAttribute("height", 200);
				const n = document.createElementNS("http://www.w3.org/2000/svg", "path");
				x.appendChild(n);
				n.setAttribute("fill", "white");
				n.setAttribute("stroke-width", 1);
				data = generateWaveform(exp[0]);
				n.setAttribute("d", data);
				v.appendChild(document.createElement("br"));
				const play = document.createElement("button");
				play.textContent = "Play Sound";
				v.appendChild(play);
				timeline = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timeline.setAttribute("height", 200);
				timeline.setAttribute("width", 2);
				timeline.setAttribute("fill", "none");
				timeline.setAttribute("x", 0);
				timelineBegin = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timelineBegin.setAttribute("height", 200);
				timelineBegin.setAttribute("width", 2);
				timelineBegin.setAttribute("fill", "none");
				timelineBegin.setAttribute("x", 0);
				timelineEnd = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timelineEnd.setAttribute("height", 200);
				timelineEnd.setAttribute("width", 2);
				timelineEnd.setAttribute("fill", "none");
				timelineEnd.setAttribute("x", 0);
				highlight = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				highlight.setAttribute("height", 200);
				highlight.setAttribute("width", 2);
				highlight.setAttribute("fill", "none");
				highlight.setAttribute("x", 0);
				x.appendChild(timeline);
				x.appendChild(timelineBegin);
				x.appendChild(timelineEnd);
				x.appendChild(highlight);
				let bpmMarks = [];
				function restartSelect() {
					timelineIter = -1;
					timelineBegin.setAttribute("fill", "none");
					timelineBegin.setAttribute("x", 0);
					timelineEnd.setAttribute("fill", "none");
					timelineEnd.setAttribute("x", 0);
					highlight.setAttribute("fill", "none");
					highlight.setAttribute("x", 0);
					timelineBeginNum = 0;
					timelineEndNum = 0;
					timelineEndNumCache = 0;
					timelineBeginAudio = 0;
					timelineEndAudio = 0;
				}
				play.onclick = () => {
					startAt = 0;
					bbb = 0;
					playSound();
				}
				//document.body.onclick = restartSelect;
				function playWithTimeline(eve) {
					let clickX = eve.clientX - /*(timelineBeginNum ? (v.getBoundingClientRect().x - window.pageXOffset) :*/ (xOff - window.scrollX);
					if (isPressingShift) {
						timelineIter++;
						switch (timelineIter) {
							case 0: {
								timelineBegin.setAttribute("x", clickX);
								timelineBegin.setAttribute("fill", "#00AAFF");
								timelineBeginNum = clickX;
								timelineBeginAudio = timelineBeginNum * sampleSkip;
								break;
							}
							case 1: {
								timelineEnd.setAttribute("x", clickX);
								timelineEnd.setAttribute("fill", "#00AAFF");
								highlight.setAttribute("fill", "#00AAFF");
								highlight.setAttribute("fill-opacity", 0.3);
								timelineEndNum = clickX;
								if (timelineEndNum < timelineBeginNum) {
									const temp = timelineEndNum;
									timelineEndNum = timelineBeginNum;
									timelineBeginNum = temp;
								}
								timelineEndNumCache = timelineEndNum / div.clientWidth * sharedBuffer.duration;
								timelineEndAudio = timelineEndNum * sampleSkip;
								highlight.setAttribute("x", timelineBeginNum);
								highlight.setAttribute("width", timelineEndNum - timelineBeginNum);
								break;
							}
							case 2: {
								restartSelect();
								break;
							}
						}
						return;
					}
					const relativeX = clickX / x.clientWidth;
					startAt = relativeX * sharedBuffer.duration; // Time in seconds

					playSound();
				}
				x.onclick = playWithTimeline;
				const label3 = document.createElement("a");
				const co = document.createElement("input");
				label3.textContent = "View at Sample-Level";
				v.appendChild(label3);
				co.type = "checkbox";
				v.appendChild(co);
				co.oninput = function() {
					if (co.checked) {
						sampleSkip = 1;
						x.setAttribute("width", exp[0].audioData.length);
						v.style.width = exp[0].audioData.length + "px";
					} else {
						sampleSkip = 480;
						if (!data) data = generateWaveform(exp[0]);
						x.setAttribute("width", exp[0].audioData.length / sampleSkip);
						x.style.marginLeft = "0px";
						v.style.width = (exp[0].audioData.length / sampleSkip) + "px";
						n.setAttribute("d", data);
					}
				}
				let count = 0;
				let yu = exp[0].audioData.length;
				window.onkeydown = function(key) {
					if (key.key === " ") {
						const s = isPressingShift;
						isPressingShift = false;
						playWithTimeline({clientX: /*(timelineIter === -1 ? (*/ v.getBoundingClientRect().x - window.pageXOffset /*) : Math.max(xOff - window.pageXOffset, (v.getBoundingClientRect().x - window.pageXOffset)))*/});
						isPressingShift = s;
					}
				}
				prevIntervalID = setInterval(function() {
					xOff = v.getBoundingClientRect().x + window.pageXOffset;
				}, 1000);
				v.appendChild(document.createElement("br"));
				const opt = document.createElement("select");
				const apply = document.createElement("button");
				const params = document.createElement("div");
				const bpm = document.createElement("button");
				v.appendChild(bpm);
				bpm.textContent = "Label BPM";
				bpm.onclick = function() {
					if (bpmMarks.length > 0) {
						for (const b of bpmMarks) b.remove();
					}
					bpmMarks = [];
					const bpmNum = Number(prompt("What is the amount of beats per minute of this track?") || NaN);
					if (!isNaN(bpmNum)) {
						if (bpmNum > 2400) {
							alert("There are too many BPM.");
							return;
						} else if (bpmNum <= 1) {
							alert("The amount of BPM is too low.")
							return;
						}
						const inc = (60 / bpmNum) * (div.clientWidth / sharedBuffer.duration);
						const data1 = document.createElementNS("http://www.w3.org/2000/svg", "path");
						data1.setAttribute("stroke", "yellow");
						data1.setAttribute("fill", "none");
						data1.setAttribute("width", div.clientWidth);
						data1.setAttribute("height", "200");
						const data2 = document.createElementNS("http://www.w3.org/2000/svg", "path");
						data2.setAttribute("stroke", "orange");
						data1.setAttribute("fill", "none");
						data2.setAttribute("width", div.clientWidth);
						data1.setAttribute("height", "200");
						let data1Data = [], data2Data = [];
						const wid = div.clientWidth;
						for (let i = 0, j = 0; i < wid; i += inc, j++) {
							if ((j & 3) === 0) data1Data.push(`M${i},0 V200`); else data2Data.push(`M${i},0 V200`);
						}
						data1.setAttribute("d", data1Data.join(" "));
						data2.setAttribute("d", data2Data.join(" "));
						x.appendChild(data1);
						x.appendChild(data2);
						bpmMarks.push(data1, data2);
					}
				}
				{
					const label = document.createElement("a");
					label.textContent = "Effect To Apply: ";
					let option = document.createElement("option");
					option.textContent = "Please select an effect";
					option.value = "placeholder";
					v.appendChild(label);
					v.appendChild(opt);
					opt.appendChild(option);
					for (let effect of effectsList) {
						option = document.createElement("option");
						option.textContent = effect[0];
						option.value = effect[4];
						opt.appendChild(option);
					}
					v.appendChild(params);
					apply.textContent = "Apply";
					v.appendChild(apply);
					let currentSelected = null, paramElements = null, effect;
					apply.onclick = async function() {
						if (currentSelected) {
							for (const expor of exp) {
								const values = [expor, ...paramElements.map((x, i) => {
									if (x.type === "checkbox") {
										return effect[5][i](x.checked);
									} else {
										return effect[5][i](x.value);
									}
								})];
								if (timelineBeginAudio !== 0) values[0] = {audioData: expor.audioData.subarray(timelineBeginAudio, timelineEndAudio), sampleRate: expor.sampleRate};
								const le = values[0].audioData.length;
								await effects[effect[4]](...values);
								if (timelineBeginAudio !== 0) {
									if (values[0].audioData.buffer !== expor.audioData.buffer) {
										if (values[0].audioData.length === timelineEndAudio - timelineBeginAudio) {
											expor.audioData.set(values[0].audioData, timelineBeginAudio);
										} else {
											const data = new Float32Array(values[0].audioData.length + expor.audioData.length - le);
											data.set(expor.audioData.subarray(0, timelineBeginAudio), 0);
											data.set(values[0].audioData, timelineBeginAudio);
											data.set(expor.audioData.subarray(timelineEndAudio, expor.audioData.length), values[0].audioData.length + timelineBeginAudio);
											expor.audioData = data;
											//timelineEndAudio = values[0].audioData.length - timelineBeginAudio;
										}
									}
								}
							}
							data = generateWaveform(exp[0]);
							sharedBuffer = audioContext.createBuffer(exp.length, exp[0].audioData.length, exp[0].sampleRate);
							const ref = sharedBuffer.getChannelData(0);
							ref.set(exp[0].audioData);
							if (exp.length === 2) {
								const ref2 = sharedBuffer.getChannelData(1);
								ref2.set(exp[1].audioData);
							}
							x.setAttribute("width", exp[0].audioData.length / sampleSkip);
							v.style.width = (exp[0].audioData.length / sampleSkip) + "px";
							n.setAttribute("d", data);
							x.onclick = playWithTimeline; // Reset playing function, just in case browsers like Chrome misbehave every time an effect is applied
							yu = exp[0].audioData.length;
						}
					}
					opt.oninput = function() {
						effect = effectsList.find(x => x[4] === opt.value);
						currentSelected = effect;
						if (effect) {
							params.innerHTML = effect[1] + "<br>" + effect[2];
							paramElements = new Array(effect[3]);
							for (let i = 0; i < paramElements.length; i++) {
								paramElements[i] = document.getElementById(effect[4] + i);
							}
						} else {
							params.innerHTML = "";
							paramElements = null;
						}
					}
				}
				v.appendChild(document.createElement("br"));
				let exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as WAV";
				exportBtn.onclick = function() {
					const metadata = {};
					const author = prompt("Who is the author of this audio? (e.g. \"John Smith\") Leave the input blank if you don't want the author to be specified.");

					if (author === "" || author === undefined || author === null) return;
					const name = prompt("What is the name of this audio? (e.g. \"Electro Dance (Techno Mix)\") Leave the input blank if you don't want the name to be specified.");
					const genre = prompt("What is the genre of this audio? (e.g. \"Techno\") Leave the input blank if you don't want the genre to be specified.");
					const notes = prompt("Any notes or comments for this audio? (e.g. \"This audio is super cool\") Leave the input blank if you don't have any notes or comments.");

					const software = prompt("What software did you use to create this audio? (e.g. \"UnnamedBruh's Audio Editor\") If input is \"UAE\" without quotes, this software's name will be appended to the audio metadata.");

					if (author) metadata["IART"] = author;
					if (name) metadata["INAM"] = name;
					if (genre) metadata["IGNR"] = genre;
					if (notes) metadata["ICMT"] = notes;
					if (software) metadata["ISFT"] = software === "UAE" ? "UnnamedBruh's Audio Editor" : software;

					const encodeBits = prompt("What are the exporting settings of the audio? (0 = 8-bit integer. 1 = 16-bit integer. 2 = 32-bit integer. 3 = 32-bit float. 4 = 64-bit float. 5 - mu-law encoding.");

					const exporters2 = timelineBeginAudio ? {audioData: exporters[0].audioData.subarray(timelineBeginAudio, timelineEndAudio), sampleRate: exporters[0].sampleRate, bits: exporters[0].bits, encoding: exporters[0].encoding, convertToWav: exporters[0].convertToWav} : exporters[0];
					const oldBits = exporters2.bits;
					if (encodeBits == 0) {
						exporters2.bits = 8;
						exporters2.encoding = "pcm";
					} else if (!encodeBits || encodeBits == 1) {
						exporters2.bits = 16;
						exporters2.encoding = "pcm";
					} else if (encodeBits == 2) {
						exporters2.bits = 32;
						exporter2s.encoding = "pcm";
					} else if (encodeBits == 3) {
						exporters2.bits = 32;
						exporters2.encoding = "pcmf32";
					} else if (encodeBits == 4) {
						exporters2.bits = 64;
						exporters2.encoding = "pcmf64";
					} else {
						exporters2.encoding = "mulaw";
					}
					
					const blob = exporters2.convertToWav(metadata);

					exporters2.bits = encodeBits;

					const link = document.createElement("a");
					link.download = (name || "exportedAudio") + ".wav";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as MP3";
				exportBtn.onclick = async function() {
					function floatTo16BitPCM(float32Array, channels) {
						const len = float32Array.length / channels;
						const buffer = new Int16Array(len);
						let s = 0;
						if (channels === 1) {
							for (let i = 0; i < len; i++) {
								s = float32Array[i];
								buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						} else {
							for (let i = 0, j = 0; i < len; i++, j+=channels) {
								s = float32Array[j];
								buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						}
						return buffer;
					}

					let sampleRate = exporters[0].sampleRate;
					const kbps = Math.ceil(Number(prompt("What is the KBPS (Kilobits Per Second) of the MP3 audio? (e.g. 64, 80, 96, 128, 192, 256, 320)")) / 16) * 16;
					if (kbps === 0 || isNaN(kbps) || kbps === undefined || kbps === null) return;

					const qual = Math.min(9, Math.max(0, prompt("What is the VBR (Variable BitRate) of the MP3 audio? (between 0 and 9. 0 = best quality and slower encoding, 9 = worst quality and faster encoding, 3 = balanced)") ?? 3));

					const channels = (exporters.length === 2) ? 2 : 1;
					const shouldSplit = channels !== 2 && confirm("Should the same buffer be split into two channels? (If so, the audio may sound a bit choppier)");

					const lossTimes = Number(prompt("How many times should the same audio be re-encoded? (for glitch-art audio)") || 1);

					let blob;

					for (let i = 0; i < lossTimes; i++) {
						let buffer = i === 0 ? exporters.map(exp => timelineBeginAudio ? exp.audioData.subarray(timelineBeginAudio, timelineEndAudio) : exp.audioData) : await audioContext.decodeAudioData(await blob.arrayBuffer());
						let altRate = buffer.sampleRate;
						if (i > 0) {
							if (buffer.numberOfChannels === 2) buffer = [buffer.getChannelData(0), buffer.getChannelData(1)]; else buffer = [buffer.getChannelData(0), buffer.getChannelData(0)];
						}
						const mp3Encoder = new lamejs.Mp3Encoder(channels, i === 0 ? sampleRate : altRate, kbps, qual);

						let mp3Data = [];

						let pcmData = [floatTo16BitPCM(buffer[0], channels === 2 && !shouldSplit ? 2 : 1)];
						const len = pcmData[0].length;
						if (channels === 1) pcmData = [pcmData[0], pcmData[0]]; else pcmData = [pcmData[0], floatTo16BitPCM(buffer[1], 2)];
						const len2 = len - 1152;
						let xx;

						for (let i = 0; i < len2; i += 1152) {
							xx = i > len2 ? len : i + 1152;
							const chunk = [pcmData[0].subarray(i, xx), pcmData[1].subarray(i, xx)];

							// For mono input, pass chunk for both channels if needed
							const mp3Chunk = mp3Encoder.encodeBuffer(chunk[0], chunk[1]);
							mp3Data.push(mp3Chunk);
						}

						mp3Data.push(mp3Encoder.flush());
						blob = new Blob(mp3Data, { type: "audio/mp3" });
					}

					const link = document.createElement("a");
					link.download = "exportedAudio.mp3";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as OGG (Vorbis format)";
				exportBtn.onclick = async function() {
					try {
						const vbr = Number(prompt("How high can the quality of the audio be? (-1.0 = worst quality, big differences, low sizes; 10.0 = best quality, nearly-neglible differences, higher sizes; 4.0 = balanced quality, minimal differences, medium sizes)") ?? 4.0) ?? 4.0;

						let blob;
						const split = exporters.length !== 2 && !!confirm("Should the audio be split into two separate channels?");

						const times = Number(prompt("How many times would the audio be re-encoded?") || 1) || 1;

						for (let i = 0; i < times; i++) {
							const encoder = await WasmMediaEncoder.createOggEncoder();

							let buffer = i === 0 ? exporters.map(exp => timelineBeginAudio ? exp.audioData.subarray(timelineBeginAudio, timelineEndAudio) : exp.audioData) : await audioContext.decodeAudioData(await blob.arrayBuffer());
							let altRate = buffer.sampleRate;
							if (i > 0) {
								if (buffer.numberOfChannels === 2) buffer = [buffer.getChannelData(0), buffer.getChannelData(1)]; else buffer = [buffer.getChannelData(0)];
							}

							encoder.configure({
								sampleRate: i === 0 ? exporters[0].sampleRate : altRate,
								channels: buffer.length + split,
								vbrQuality: vbr,
							});
							
							const encodedData = encoder.encode(split || buffer.length === 2 ? [buffer[0], buffer[1]] : [buffer[0]]);
							const encodedCopy = new Uint8Array(encodedData).buffer;
							const finalData = encoder.finalize();

							blob = new Blob([encodedCopy, finalData], { type: "audio/ogg" });
						}

						const link = document.createElement("a");
						link.download = "exportedAudio.ogg";
						link.href = URL.createObjectURL(blob);
						link.click();
						link.remove();
					} catch (err) {
						alert("It seems like the OGG Vorbis codec is supported, but not yet available. READ BELOW:\n\nA network is required to export your audio into the OGG format. The encoder itself is stored in an online module server (UNPKG.com), then loaded into this audio editor. (This means your audio track or other invaluable information isn't tracked, or sent to any server; just encoded directly in your browser!)");
						console.log(err.message, err.stack);
					}
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as FLAC (libflac.js)";
				exportBtn.onclick = async function() { // This function was written entirely by Claude Sonnet 4.5. I did not make any modifications to the original code, aside from the fact that I padded the whitespace.
					try {
						// Setup for collecting encoded data
						const encBuffer = [];

						// Callback to receive encoded FLAC data
						function write_callback_fn(buffer) {
							// Copy the buffer immediately (same issue as with OGG Vorbis!)
							const copy = new Uint8Array(buffer);
							encBuffer.push(copy);
						}

						// Create encoder
						const CHANNELS = exporters.length;
						const SAMPLERATE = exporters[0].sampleRate;
						const BPS = 24; // 24-bit encoding
						const COMPRESSION = Number(prompt("What is the quality of the audio? (In accurate terms, how aggressive is the lossless compression? 0 = fastest compression, largest file, 8 = slower compression, smaller file, 5 = balanced compression, balanced file)") ?? 5);
						const VERIFY = false;
						const BLOCK_SIZE = 0; // 0 = let encoder decide

						const flac_encoder = Flac.create_libflac_encoder(
							SAMPLERATE,
							CHANNELS,
							BPS,
							COMPRESSION,
							timelineBeginAudio ? (timelineEndAudio - timelineBeginAudio) : exporters[0].audioData.length, // total_samples (0 = unknown)
							VERIFY,
							BLOCK_SIZE
						);

						// Initialize encoder with write callback
						const initStatus = Flac.init_encoder_stream(
							flac_encoder,
							write_callback_fn
						);

						if (initStatus !== 0) {
							throw new Error("FLAC encoder initialization failed");
						}

						// Convert Float32 to 24-bit integers (packed as Int32Array)
						const audioData = exporters.map(i => timelineBeginAudio ? 
							i.audioData.subarray(timelineBeginAudio, timelineEndAudio) :
							i.audioData);

						const int24Buffer = new Int32Array(audioData[0].length * audioData.length);
						if (audioData.length === 2) {
							const aa = audioData[0];
							const ab = audioData[1];
							for (let i = 0, j = 0; i < int24Buffer.length; i += 2, j++) {
								int24Buffer[i] = Math.round(aa[j] * 8388607);
								int24Buffer[i + 1] = Math.round(ab[j] * 8388607);
							}
						} else {
							const aa = audioData[0];
							for (let i = 0; i < aa.length; i++) {
								int24Buffer[i] = Math.round(aa[i] * 8388607);
							}
						}

						// Encode
						const encodeStatus = Flac.FLAC__stream_encoder_process_interleaved(
							flac_encoder,
							int24Buffer,
							audioData[0].length
						);

						if (!encodeStatus) {
							throw new Error("FLAC encoding failed");
						}

						// Finish encoding
						const finishStatus = Flac.FLAC__stream_encoder_finish(flac_encoder);

						if (!finishStatus) {
							throw new Error("FLAC finalization failed");
						}

						// Clean up
						Flac.FLAC__stream_encoder_delete(flac_encoder);

						// Combine all encoded chunks
						const totalLength = encBuffer.reduce((sum, chunk) => sum + chunk.length, 0);
						const flacData = new Uint8Array(totalLength);
						let offset = 0;
						for (const chunk of encBuffer) {
							flacData.set(chunk, offset);
							offset += chunk.length;
						}

						// Download
						const blob = new Blob([flacData], { type: "audio/flac" });
						const link = document.createElement("a");
						link.download = "exportedAudio.flac";
						link.href = URL.createObjectURL(blob);
						link.click();
						link.remove();
		
					} catch (err) {
						alert("The FLAC encoding failed: " + err.message);
						console.error(err);
					}
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as LSAC (LoSsy Audio Codec)";
				exportBtn.onclick = function() {
					const blob = encodeLSAC(exporters[0].audioData, exporters[0].sampleRate);

					const link = document.createElement("a");
					link.download = "exportedAudio.lsac";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as FBAC (Frame-Based Audio Codec)";
				exportBtn.onclick = function() {
					const blob = encodeFBAC(exporters[0].audioData, exporters[0].sampleRate);

					const link = document.createElement("a");
					link.download = "exportedAudio.fbac";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				window.onscroll = function() {
					apply.style.marginLeft = window.scrollX + "px";
					opt.style.marginLeft = apply.style.marginLeft;
					params.style.marginLeft = apply.style.marginLeft;
					selectLabel.style.marginLeft = apply.style.marginLeft;
					selectLabel.style.wordWrap = "keep-all";
					selectLabel.style.whiteSpace = "nowrap";
					if (window.scrollX > window.innerWidth - selectLabel.getBoundingClientRect().width) selectBox.style.marginLeft = apply.style.marginLeft; else selectBox.style.marginLeft = "";
					if (sampleSkip === 1) {
						count++;
						if (count < 4) return;
						count = 0;
						let data2 = ["M 0,100 L 0,100"];
						let xn = window.scrollX;
						x.setAttribute("width", window.innerWidth);
						x.style.marginLeft = (xn - xOff) + "px";
						const len = Math.min(xn - xOff + window.innerWidth, yu), y = exp[0].audioData;
						let prev = 0, val = y[0];
						let ep = 0.004;
						for (let i = xn, j = 0; i < len; i++, j++) {
							if (Math.abs(prev - val) >= ep) {
								data2.push("L " + j + "," + Math.round(100 + val * 100));
								prev = val;
							}
							val = y[i];
						}
						data2.push("L " + (len / sampleSkip) + ",100");
						n.setAttribute("d", data2.join(" "));
					}
				}
				effects["trim"] = function() {
					for (let i = 0; i < exporters.length; i++) {
						if (timelineBeginAudio) exporters[i].audioData = exporters[i].audioData.subarray(timelineBeginAudio, timelineEndAudio); else alert("You have not selected any portion of the audio yet.");
					}
				}
				ed = v;
				div = x;
			}

			effectsList.push([
				"Trim",
				"Removes all of the contents that is not selected by the blue selection box.",
				'',
				0,
				"trim",
				[]
			]);

			audioInput.oninput = async function(eve) {
				if (eve.target.files.length === 0) return;
				let firstFile = eve.target.files[0];
				let secondFile = eve.target.files[1];
				let isCorrect;
				function swapFiles() {
					const temp = secondFile;
					secondFile = firstFile;
					firstFile = temp;
				}
				if (secondFile) {
					isCorrect = confirm("It seems like you selected two audio files. Is this correct?");
					if (isCorrect) alert("*This editor cannot interpret the second file as raw audio because the maintainer of this editor has not implemented this feature... yet." + (whichInterpret ? " Not that the audio won't be decoded." : ""));
					if (!confirm("Which file is the one you want to edit?\nOK = " + firstFile.name.trim() + "\nCancel (or X) = " + secondFile.name.trim())) {
						swapFiles();
					}
				}
				if (!whichInterpret && (firstFile.name.endsWith(".lsac") || firstFile.name.endsWith(".fbac"))) {
					try {
						exporters = null;
						if (ed) {
							ed.innerHTML = "";
							ed.remove();
							ed = null;
						}
						data = null;
						sampleData = null;
						sampleSkip = 480;
						let result = 0;
						if (firstFile.name.endsWith(".lsac")) result = await decodeLSAC(firstFile); else result = await decodeFBAC(firstFile);
						sharedBuffer = audioContext.createBuffer(1, result.samples.length, result.sampleRate);
						const len = result.samples.length;
						const bufferData = sharedBuffer.getChannelData(0);
						const samples = result.samples;
						for (let i = 0; i < len; i++) {
							bufferData[i] = samples[i];
						}
						exporters = [new AudioExporter(result.samples, result.sampleRate, 1, 32)];
						loadDiv(exporters[0]);
					} catch (err) {
						alert("The audio could not be properly loaded! Due to unhelpful strip-aways from viewing metadata, we cannot provide much info on what exactly failed.");
						console.log(err.message + err.stack);
					}
				} else {
					const fileReader = new FileReader();
					fileReader.onload = async function(event) {
						try {
							exporters = null;
							if (ed) {
								ed.innerHTML = "";
								ed.remove();
								ed = null;
							}
							data = null;
							sampleData = null;
							sampleSkip = 480;
							if (whichInterpret) {
								const data = event.target.result;
								const type = Number(prompt("How will the audio be interpreted? (0 = integers, 1 = floats)"));
								const bits = Math.max(prompt("What is the bits per sample of the audio?") >> 3, 1);
								sharedBuffer = audioContext.createBuffer(1, data.byteLength / bits, prompt("What is the samplerate of the audio?") || 48000);
								const channel = sharedBuffer.getChannelData(0);
								const len = sharedBuffer.length;
								const buffer = new Uint8Array(data);
								if (type === 0) {
									if (bits === 1) {
										const bufferInt = new Int8Array(data);
										for (let i = 0; i < len; i++) {
											channel[i] = bufferInt[i] / 0x80;
										}
									} else if (bits === 2) {
										for (let i = 0, j = 0; i < len; i += bits, j++) {
											channel[j] = ((buffer[i + 1] << 8) | buffer[i]) / 0x8000 - 0.5;
										}
									} else if (bits === 3) {
										for (let i = 0, j = 0; i < len; i += bits, j++) {
											channel[j] = ((buffer[i + 2] << 16) | (buffer[i + 1] << 8) | buffer[i]) / 0x800000 - 0.5;
										}
									} else if (bits === 4) {
										for (let i = 0, j = 0; i < len; i += bits, j++) {
											channel[j] = ((buffer[i + 3] << 24) | (buffer[i + 2] << 16) | (buffer[i + 1] << 8) | buffer[i]) / 0x80000000 - 0.5;
										}
									}
								} else if (type === 1) {
									const s = Math.sign;
									if (bits === 4) {
										const f = new Float32Array(data.slice(0, data.byteLength >> 2 << 2));
										const lenF = f.length;
										let x;
										for (let i = 0; i < lenF; i++) {
											x = f[i];
											channel[i] = (x === Infinity ? 1 : (x === -Infinity ? -1 : (isNaN(x) ? 0 : x))) || 0;
											channel[i] = channel[i] > 1 ? 1 : (channel[i] < -1 ? -1 : channel[i]);
										}
									} else if (bits === 8) {
										const f = new Float64Array(data.slice(0, data.byteLength >> 3 << 3));
										const lenF = f.length;
										let x;
										for (let i = 0; i < lenF; i++) {
											x = f[i];
											channel[i] = (x === Infinity ? 1 : (x === -Infinity ? -1 : (isNaN(x) ? 0 : x))) || 0;
											channel[i] = channel[i] > 1 ? 1 : (channel[i] < -1 ? -1 : channel[i]);
										}
									}
								}
								exporters = [new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32)];
								loadDiv(exporters);
								return;
							}
							sharedBuffer = await audioContext.decodeAudioData(event.target.result);
							if (isCorrect) {
								alert("The first audio file was decoded.");
								const fileReader2 = new FileReader();
								let secondSharedBuffer;
								await new Promise(function(resolve) {
									try {
										fileReader2.onload = async function(eve) {
											try {
												secondSharedBuffer = await audioContext.decodeAudioData(eve.target.result);
											} catch {
												alert("Looks like the second audio file has failed to be decoded! However, you can still edit the main audio.");
											}
											if (secondSharedBuffer && confirm("Would you like to layer both audio files together?")) {
												let inway = Number(prompt("Alright! Which way should the audio editor layer the audio files together? (0 = audioFile1 + audioFile2, 1 = audioFile1 - audioFile2, 2 = audioFile2 - audioFile1") || 0);
												if (sharedBuffer.sampleRate === secondSharedBuffer.sampleRate && sharedBuffer.numberOfChannels === secondSharedBuffer.numberOfChannels) {
													let len;
													if (sharedBuffer.length > secondSharedBuffer.length) len = secondSharedBuffer.length; else len = sharedBuffer.length;
													if (inway === 0) {
														for (let i = 0; i < secondSharedBuffer.numberOfChannels; i++) {
															const pointer1 = sharedBuffer.getChannelData(i);
															const pointer2 = secondSharedBuffer.getChannelData(i);
															for (let j = 0; j < len; j++) {
																pointer1[j] += pointer2[j];
															}
														}
													} else if (inway === 1 || inway === 2 || inway === 3 || inway === 4) {
														if (inway === 3 || inway === 4) {
															for (let i = 0; i < secondSharedBuffer.numberOfChannels; i++) {
																const pointer = (inway === 3 ? sharedBuffer.getChannelData(i) : secondSharedBuffer.getChannelData(i));
																for (let j = 0; j < len; j++) {
																	pointer[j] *= 0.5;
																}
															}
															inway -= 2;
														}
														for (let i = 0; i < secondSharedBuffer.numberOfChannels; i++) {
															let pointer1;
															let pointer2;
															if (inway === 1) {
																pointer1 = sharedBuffer.getChannelData(i);
																pointer2 = secondSharedBuffer.getChannelData(i);
															} else {
																pointer2 = sharedBuffer.getChannelData(i);
																pointer1 = secondSharedBuffer.getChannelData(i);
															}
															for (let j = 0; j < len; j++) {
																pointer1[j] -= pointer2[j];
															}
														}
													}
												} else alert("Looks like the audio files' metadata doesn't exactly match each other well! You can still edit the main audio, though.");
											}
											resolve();
										}
										fileReader2.readAsArrayBuffer(secondFile);
									} catch {
										alert("Looks like the second audio file has failed to be decoded! However, you can still edit the main audio.");
										resolve();
									}
								});
							}
							const channelNum = Math.max(1, Math.min(+prompt("Which channel should be imported for editing? Pick a channel from 1 to " + sharedBuffer.numberOfChannels + ". (Editing multiple channels at once isn't an option due to the maintainer's preferred simplicity.)") || 1, sharedBuffer.numberOfChannels)) - 1;
							const channel = sharedBuffer.getChannelData(channelNum);
							let isProcessed = false;
							if (sharedBuffer.numberOfChannels === 2) {
								if (confirm("Should the current channel be subtracted by another? (If you want to only edit the audio, just press Cancel)")) {
									const channelOtherNum = sharedBuffer.numberOfChannels - channelNum - 1;
									const len = channel.length;
									const channelOther = sharedBuffer.getChannelData(channelOtherNum);
									const choice = Number(prompt("Okay then! Which formula do you want to choose? (0 = channel" + channelNum + " - otherChannel | 1 = channel" + channelNum + " * 2 - otherChannel | 2 = channel" + channelNum + " - (otherChannel - channel" + channelNum + ") / 2 | 3 = 2 but otherChannel" + channelNum + " * 2 | 4 = channel" + channelNum + " + otherChannel)"));
									if (choice === 0) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i];
										}
									} else if (choice === 1) {
										for (let i = 0; i < len; i++) {
											channel[i] = channelOther[i] - channel[i];
										}
									} else if (choice === 2) {
										for (let i = 0; i < len; i++) {
											channel[i] -= Math.abs(channelOther[i] - channel[i]);
										}
									} else if (choice === 3) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i] * 2 - channel[i];
										}
									} else if (choice === 3.5) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i] - channel[i] * 2;
										}
									} else if (choice === 4) {
										for (let i = 0; i < len; i++) {
											channel[i] = (channel[i] + channelOther[i]) * 0.5;
										}
									}
									isProcessed = true;
								}
							}
							const stereo = sharedBuffer.numberOfChannels === 2 && !isProcessed && confirm("Do you want the final audio to be stereo?");
							if (sharedBuffer.numberOfChannels > 1 && !stereo) { // Normalize playback, since only one channel is being loaded. If other channels are playing while one is selected, it can suddenly sound "mono" if an effect is applied, which confuses the user
								for (let i = 0; i < sharedBuffer.numberOfChannels; i++) {
									if (i === channelNum) continue;
									const silentBuffer = sharedBuffer.getChannelData(i);
									if (silentBuffer) silentBuffer.set(channel);
								}
							}
							if (stereo) exporters = [new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32), new AudioExporter(sharedBuffer.getChannelData(1 - channelNum), sharedBuffer.sampleRate, 1, 32)];
							else exporters = [new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32)];
							loadDiv(exporters);
						} catch (err) {
							alert("The audio could not be properly loaded! We couldn't gather any info on what exactly failed, so the best we can say is: try selecting another audio file, or using another browser.");
							console.log(err.message + err.stack);
						}
					}
					fileReader.readAsArrayBuffer(firstFile);
				}
			}
			tick();
		</script>
	</body>
</html>
