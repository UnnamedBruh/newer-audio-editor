<!DOCTYPE html>
<html lang="en">
	<head>
		<style>
			body {
				background-color: black;
				color: white;
				font-family: Arial, sans-serif;
				min-width: 100vw;
			}
			div {
				border-radius: 8px;
				background-color: rgb(30, 30, 30);
			}
		</style>
	</head>
	<body>
		<script src="audioEditor.js"></script>
		<script src="audioExporter.js"></script>
		<script src="audioEffects.js"></script>
		<script src="audioLSAC.js"></script>
		<script src="audioFBAC.js"></script>
		<script src="lame.min.js"></script>
		Volume (<a id="la" style="width: 100px">100</a>%): <input type="range" id="vol" min="0" max="10" step="0.01" value="1" style="width: 100%"><br>
		Volume Multiplier (<a id="la2" style="width: 100px">100</a>%): <input type="range" id="vol2" min="0" max="10" step="0.01" value="1" style="width: 100%"><br>
		Selecting A Certain Region? <input type="checkbox" id="select">
		<h1>Audio Editor</h1>
		<p>I've been trying to think of ways to refine it, and I've also been watching YouTube videos, which is the reason why I barely worked on anything. But finally, the audio editor is here!</p>
		Current Audio File: <input type="file" id="aud" accept=".wav, .mp3, .ogg, .flac, .aac, .weba, .m4v, .m4a, .mp4, .3gp, .3g2, .webm, .lsac, .fbac"><br>
		<button id="which">Decode The Audio File</button>
		<script>
			const audioContext = new (window.AudioContext || window.webkitAudioContext)();
			const audioInput = document.getElementById("aud"), volume = document.getElementById("vol"), label = document.getElementById("la"), volume2 = document.getElementById("vol2"), label2 = document.getElementById("la2"), selectBox = document.getElementById("select");
			let exporters = null;
			let sharedBuffer = null, src = null, whenPlayed = 0, playing = false, timeline = null, timelineBegin = null, timelineEnd = null, highlight = null, timelineBeginNum = 0, timelineEndNum = 0, timelineEndNumCache = 0, timelineIter = -1, isPressingShift = false, startAt = 0, bbb = 0, ed = null, div = null, data = null, skipSample = 480, volumeWarning = true, prevIntervalID = null, xOff, skipSampleUnround = 480;
			let gainNode = audioContext.createGain();
			const interpretFiles = document.getElementById("which");
			let whichInterpret = false;
			selectBox.oninput = function() {
				isPressingShift = selectBox.checked;
			}
			interpretFiles.onclick = function() {
				whichInterpret = !whichInterpret;
				interpretFiles.textContent = whichInterpret ? "Treat File Data As Audio" : "Decode The Audio File";
				audioInput.accept = whichInterpret ? "*" : ".wav, .mp3, .ogg, .flac, .aac, .weba, .m4v, .m4a, .mp4, .3gp, .3g2, .webm, .lsac, .fbac";
			}
			gainNode.connect(audioContext.destination);
			gainNode.gain.value = 1;
			volume.oninput = function() {
				if (volumeWarning) {
					volumeWarning = false;
					alert("Moving the knob to the right can cause incredibly loud results! Please use the volume sliders responsibly and ethically, as these are very experimental features.");
					volume.value = 1;
				}
				let x = +volume.value;
				if (x > 0.9 && x < 1.1) x = volume.value = 1;
				label.textContent = Math.round(x * 100);
				label.textContent = label.textContent;
				gainNode.gain.value = x * +volume2.value;
				if (x >= +volume.max / 1.1) {
					volume.max *= 10;
					volume.disabled = true;
					document.onmouseup = function() {
						volume.disabled = false;
						document.onmouseup = null;
					}
				}
			}
			volume2.oninput = function() {
				if (volumeWarning) {
					volumeWarning = false;
					alert("Moving the knob to the right can cause incredibly loud results! Please use the volume sliders responsibly and ethically, as these are very experimental features.");
					volume.value = 1;
				}
				let x = +volume2.value;
				if (x > 0.9 && x < 1.1) x = volume2.value = 1;
				label2.textContent = Math.round(x * 100);
				label2.textContent = label2.textContent;
				gainNode.gain.value = x * +volume.value;
				if (x >= +volume2.max / 1.1) {
					volume2.max *= 10;
					volume2.disabled = true;
					document.body.onmouseup = function() {
						volume2.disabled = false;
						document.body.onmouseup = null;
					}
				}
			}
			function tick() {
				if (timeline && playing) {
					let x = (Date.now() - whenPlayed) / 1000;
					if (sampleSkip === 1) {
						timeline.setAttribute("x", x * sharedBuffer.sampleRate / sampleSkip + bbb - window.pageXOffset);
					} else {
						timeline.setAttribute("x", x * sharedBuffer.sampleRate / sampleSkip + bbb);
					}
					if (timelineEndNum !== 0 && x > timelineEndNumCache) {
						playing = false;
						src.stop();
					}
				}
				requestAnimationFrame(() => tick());
			}
			function playSound() {
				if (!sharedBuffer) return;
				if (src) {
					src.onended = function() {};
					src.stop();
				}
				src = audioContext.createBufferSource();
				src.buffer = sharedBuffer;
				src.connect(gainNode);
				startAt += timelineBeginNum / div.clientWidth * sharedBuffer.duration;
				src.start(0, startAt);
				whenPlayed = Date.now() - startAt * 1000;
				playing = true;
				if (timeline) timeline.setAttribute("fill", "red");
				src.onended = function() {
					playing = false;
					timeline.setAttribute("fill", "none");
				}
			}
			function generateWaveform(exp) {
				let data2 = ["M 0,100 L 0,100"];
				const len = exp.audioData.length, y = exp.audioData;
				let prev = 0, val;
				let ep = 0.004;
				val = y[0];
				let b = 0;
				for (let i = 0, j = 0; i < len; i = b, j++) {
					b = i + sampleSkip;
					if (Math.abs(prev - val) >= ep) {
						data2.push("L " + j + "," + Math.round(100 + val * 100));
						val = y[b] || 0;
					}
					prev = y[i];
				}
				data2.push("L " + (len / sampleSkip) + ",100");
				return data2.join(" ");
			}
			function loadDiv(exp) {
				if (prevIntervalID !== undefined) clearInterval(prevIntervalID);
				const v = document.createElement("div");
				const x = document.createElementNS("http://www.w3.org/2000/svg", "svg");
				document.body.appendChild(v);
				v.appendChild(x);
				x.setAttribute("width", exp.audioData.length / sampleSkip);
				v.style.width = (exp.audioData.length / sampleSkip) + "px";
				x.setAttribute("height", 200);
				const n = document.createElementNS("http://www.w3.org/2000/svg", "path");
				x.appendChild(n);
				n.setAttribute("fill", "white");
				n.setAttribute("stroke-width", 1);
				data = generateWaveform(exp);
				n.setAttribute("d", data);
				v.appendChild(document.createElement("br"));
				const play = document.createElement("button");
				play.textContent = "Play Sound";
				v.appendChild(play);
				timeline = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timeline.setAttribute("height", 200);
				timeline.setAttribute("width", 2);
				timeline.setAttribute("fill", "none");
				timeline.setAttribute("x", 0);
				timelineBegin = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timelineBegin.setAttribute("height", 200);
				timelineBegin.setAttribute("width", 2);
				timelineBegin.setAttribute("fill", "none");
				timelineBegin.setAttribute("x", 0);
				timelineEnd = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				timelineEnd.setAttribute("height", 200);
				timelineEnd.setAttribute("width", 2);
				timelineEnd.setAttribute("fill", "none");
				timelineEnd.setAttribute("x", 0);
				highlight = document.createElementNS("http://www.w3.org/2000/svg", "rect");
				highlight.setAttribute("height", 200);
				highlight.setAttribute("width", 2);
				highlight.setAttribute("fill", "none");
				highlight.setAttribute("x", 0);
				x.appendChild(timeline);
				x.appendChild(timelineBegin);
				x.appendChild(timelineEnd);
				x.appendChild(highlight);
				function restartSelect() {
					timelineIter = -1;
					timelineBegin.setAttribute("fill", "none");
					timelineBegin.setAttribute("x", 0);
					timelineEnd.setAttribute("fill", "none");
					timelineEnd.setAttribute("x", 0);
					highlight.setAttribute("fill", "none");
					highlight.setAttribute("x", 0);
					timelineBeginNum = 0;
					timelineEndNum = 0;
					timelineEndNumCache = 0;
					timelineBeginAudio = 0;
					timelineEndAudio = 0;
				}
				play.onclick = () => {
					startAt = 0;
					bbb = 0;
					playSound();
				}
				//document.body.onclick = restartSelect;
				function playWithTimeline(eve) {
					const clickX = eve.clientX - xOff + window.scrollX;
					if (isPressingShift) {
						timelineIter++;
						switch (timelineIter) {
							case 0: {
								timelineBegin.setAttribute("x", clickX);
								timelineBegin.setAttribute("fill", "#00AAFF");
								timelineBeginNum = clickX;
								timelineBeginAudio = timelineBeginNum * sampleSkip;
								break;
							}
							case 1: {
								timelineEnd.setAttribute("x", clickX);
								timelineEnd.setAttribute("fill", "#00AAFF");
								highlight.setAttribute("fill", "#00AAFF");
								highlight.setAttribute("fill-opacity", 0.3);
								timelineEndNum = clickX;
								if (timelineEndNum < timelineBeginNum) {
									const temp = timelineEndNum;
									timelineEndNum = timelineBeginNum;
									timelineBeginNum = temp;
								}
								timelineEndNumCache = timelineEndNum / div.clientWidth * sharedBuffer.duration;
								timelineEndAudio = timelineEndNum * sampleSkip;
								highlight.setAttribute("x", timelineBeginNum);
								highlight.setAttribute("width", timelineEndNum - timelineBeginNum);
								break;
							}
							case 2: {
								restartSelect();
								break;
							}
						}
						return;
					}
					const relativeX = clickX / x.clientWidth;
					startAt = relativeX * sharedBuffer.duration; // Time in seconds

					playSound();
				}
				x.onclick = playWithTimeline;
				const label3 = document.createElement("a");
				const co = document.createElement("input");
				label3.textContent = "View at Sample-Level";
				v.appendChild(label3);
				co.type = "checkbox";
				v.appendChild(co);
				co.oninput = function() {
					if (co.checked) {
						sampleSkip = 1;
						x.setAttribute("width", exp.audioData.length);
						v.style.width = exp.audioData.length + "px";
					} else {
						sampleSkip = 480;
						if (!data) data = generateWaveform(exp);
						x.setAttribute("width", exp.audioData.length / sampleSkip);
						x.style.marginLeft = "0px";
						v.style.width = (exp.audioData.length / sampleSkip) + "px";
						n.setAttribute("d", data);
					}
				}
				let count = 0;
				let yu = exp.audioData.length;
				window.onscroll = function() {
					if (sampleSkip === 1) {
						if (count++ < 4) return;
						count = 0;
						let data2 = ["M 0,100 L 0,100"];
						let xn = window.scrollX;
						x.setAttribute("width", window.innerWidth);
						x.style.marginLeft = (xn - xOff) + "px";
						const len = Math.min(xn - xOff + window.innerWidth, yu), y = exp.audioData;
						let prev = 0, val = y[0];
						let ep = 0.004;
						for (let i = xn, j = 0; i < len; i++, j++) {
							if (Math.abs(prev - val) >= ep) {
								data2.push("L " + j + "," + Math.round(100 + val * 100));
								prev = val;
							}
							val = y[j];
						}
						data2.push("L " + (len / sampleSkip) + ",100");
						n.setAttribute("d", data2.join(" "));
					}
				}
				prevIntervalID = setInterval(function() {
					xOff = v.getBoundingClientRect().x + window.pageXOffset;
				}, 1000);
				v.appendChild(document.createElement("br"));
				const opt = document.createElement("select");
				{
					const label = document.createElement("a");
					label.textContent = "Effect To Apply: ";
					let option = document.createElement("option");
					option.textContent = "Please select an effect";
					option.value = "placeholder";
					v.appendChild(label);
					v.appendChild(opt);
					opt.appendChild(option);
					for (let effect of effectsList) {
						option = document.createElement("option");
						option.textContent = effect[0];
						option.value = effect[4];
						opt.appendChild(option);
					}
					const params = document.createElement("div");
					v.appendChild(params);
					const apply = document.createElement("button");
					apply.textContent = "Apply";
					v.appendChild(apply);
					let currentSelected = null, paramElements = null, effect;
					apply.onclick = function() {
						if (currentSelected) {
							const values = [exp, ...paramElements.map((x, i) => {
								if (x.type === "checkbox") {
									return effect[5][i](x.checked);
								} else {
									return effect[5][i](x.value);
								}
							})];
							if (timelineBeginAudio !== 0) values[0] = {audioData: exp.audioData.subarray(timelineBeginAudio, timelineEndAudio), sampleRate: exp.sampleRate};
							effects[effect[4]](...values);
							data = generateWaveform(exp);
							sharedBuffer = audioContext.createBuffer(1, exp.audioData.length, exp.sampleRate);
							const ref = sharedBuffer.getChannelData(0);
							/*for (let i = 0; i < ref.length; i++) {
								ref[i] = exp.audioData[i];
							}*/
							ref.set(exp.audioData);
							x.setAttribute("width", exp.audioData.length / sampleSkip);
							v.style.width = (exp.audioData.length / sampleSkip) + "px";
							n.setAttribute("d", data);
							x.onclick = playWithTimeline; // Reset playing function, just in case browsers like Chrome misbehave every time an effect is applied
						}
					}
					opt.oninput = function() {
						effect = effectsList.find(x => x[4] === opt.value);
						currentSelected = effect;
						if (effect) {
							params.innerHTML = effect[1] + "<br>" + effect[2];
							paramElements = new Array(effect[3]);
							for (let i = 0; i < paramElements.length; i++) {
								paramElements[i] = document.getElementById(effect[4] + i);
							}
						} else {
							params.innerHTML = "";
							paramElements = null;
						}
					}
				}
				v.appendChild(document.createElement("br"));
				let exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as WAV";
				exportBtn.onclick = function() {
					const metadata = {};
					const author = prompt("Who is the author of this audio? (e.g. \"John Smith\") Leave the input blank if you don't want the author to be specified.");

					if (author === "" || author === undefined || author === null) return;
					const name = prompt("What is the name of this audio? (e.g. \"Electro Dance (Techno Mix)\") Leave the input blank if you don't want the name to be specified.");
					const genre = prompt("What is the genre of this audio? (e.g. \"Techno\") Leave the input blank if you don't want the genre to be specified.");
					const notes = prompt("Any notes or comments for this audio? (e.g. \"This audio is super cool\") Leave the input blank if you don't have any notes or comments.");

					const software = prompt("What software did you use to create this audio? (e.g. \"UnnamedBruh's Audio Editor\") If input is \"UAE\" without quotes, this software's name will be appended to the audio metadata.");

					if (author) metadata["IART"] = author;
					if (name) metadata["INAM"] = name;
					if (genre) metadata["IGNR"] = genre;
					if (notes) metadata["ICMT"] = notes;
					if (software) metadata["ISFT"] = software === "UAE" ? "UnnamedBruh's Audio Editor" : software;

					const encodeBits = prompt("What are the exporting settings of the audio? (0 = 8-bit integer. 1 = 16-bit integer. 2 = 32-bit integer. 3 = 32-bit float. 4 = 64-bit float. 5 - mu-law encoding.");
					const oldBits = exporters.bits;
					if (encodeBits == 0) {
						exporters.bits = 8;
						exporters.encoding = "pcm";
					} else if (!encodeBits || encodeBits == 1) {
						exporters.bits = 16;
						exporters.encoding = "pcm";
					} else if (encodeBits == 2) {
						exporters.bits = 32;
						exporters.encoding = "pcm";
					} else if (encodeBits == 3) {
						exporters.bits = 32;
						exporters.encoding = "pcmf32";
					} else if (encodeBits == 4) {
						exporters.bits = 64;
						exporters.encoding = "pcmf64";
					} else {
						exporters.encoding = "mulaw";
					}
					
					const blob = exporters.convertToWav(metadata);

					exporters.bits = encodeBits;

					const link = document.createElement("a");
					link.download = (name || "exportedAudio") + ".wav";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as LSAC (LoSsy Audio Codec)";
				exportBtn.onclick = function() {
					const blob = encodeLSAC(exporters.audioData, exporters.sampleRate);

					const link = document.createElement("a");
					link.download = "exportedAudio.lsac";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as FBAC (Frame-Based Audio Codec)";
				exportBtn.onclick = function() {
					const blob = encodeFBAC(exporters.audioData, exporters.sampleRate);

					const link = document.createElement("a");
					link.download = "exportedAudio.fbac";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				exportBtn = document.createElement("button");
				v.appendChild(exportBtn);
				exportBtn.textContent = "Export as MP3";
				exportBtn.onclick = async function() {
					function floatTo16BitPCM(float32Array, channels) {
						const len = float32Array.length / channels;
						const buffer = new Int16Array(len);
						let s = 0;
						if (channels === 1) {
							for (let i = 0; i < len; i++) {
								s = float32Array[i];
								buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						} else {
							for (let i = 0, j = 0; i < len; i++, j+=channels) {
								s = float32Array[j];
								buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
							}
						}
						return buffer;
					}

					let sampleRate = exporters.sampleRate;
					const kbps = Math.ceil(Number(prompt("What is the KBPS (Kilobits Per Second) of the MP3 audio? (e.g. 64, 80, 96, 128, 192, 256, 320)")) / 16) * 16;
					if (kbps === 0 || isNaN(kbps) || kbps === undefined || kbps === null) return;

					const qual = Math.min(9, Math.max(0, prompt("What is the VBR (Variable BitRate) of the MP3 audio? (between 0 and 9. 0 = best quality and slower encoding, 9 = worst quality and faster encoding, 3 = balanced)") || 3));

					const channels = confirm("Should the same buffer be split into two channels? (If so, the audio may sound a bit choppier)") + 1;

					const lossTimes = Number(prompt("How many times should the same audio be re-encoded? (for glitch-art audio)") || 1);

					let blob;

					for (let i = 0; i < lossTimes; i++) {
						let buffer = i === 0 ? exporters.audioData : await audioContext.decodeAudioData(await blob.arrayBuffer());
						let altRate = buffer.sampleRate;
						if (i > 0) buffer = buffer.getChannelData(0);
						const mp3Encoder = new lamejs.Mp3Encoder(channels, i === 0 ? sampleRate : altRate, kbps, qual);

						let mp3Data = [];

						const pcmData = floatTo16BitPCM(buffer, channels);
						const len = pcmData.length;
						const len2 = len - 1152;

						for (let i = 0; i < len2; i += 1152) {
							const chunk = pcmData.subarray(i, i > len2 ? len : i + 1152);

							// For mono input, pass chunk for both channels if needed
							const mp3Chunk = mp3Encoder.encodeBuffer(chunk, chunk);
							mp3Data.push(mp3Chunk);
						}

						mp3Data.push(mp3Encoder.flush());
						blob = new Blob(mp3Data, { type: "audio/mp3" });
					}

					const link = document.createElement("a");
					link.download = "exportedAudio.mp3";
					link.href = URL.createObjectURL(blob);
					link.click();
					link.remove();
				}
				ed = v;
				div = x;
			}
			audioInput.oninput = async function(eve) {
				if (eve.target.files.length === 0) return;
				const firstFile = eve.target.files[0];
				if (!whichInterpret && (firstFile.name.endsWith(".lsac") || firstFile.name.endsWith(".fbac"))) {
					try {
						exporters = null;
						if (ed) {
							ed.innerHTML = "";
							ed.remove();
							ed = null;
						}
						data = null;
						sampleData = null;
						sampleSkip = 480;
						let result = 0;
						if (firstFile.name.endsWith(".lsac")) result = await decodeLSAC(firstFile); else result = await decodeFBAC(firstFile);
						sharedBuffer = audioContext.createBuffer(1, result.samples.length, result.sampleRate);
						const len = result.samples.length;
						const bufferData = sharedBuffer.getChannelData(0);
						const samples = result.samples;
						for (let i = 0; i < len; i++) {
							bufferData[i] = samples[i];
						}
						exporters = new AudioExporter(result.samples, result.sampleRate, 1, 32);
						loadDiv(exporters);
					} catch (err) {
						alert("The audio could not be properly loaded! Due to unhelpful strip-aways from viewing metadata, we cannot provide much info on what exactly failed.");
						console.log(err.message + err.stack);
					}
				} else {
					const fileReader = new FileReader();
					fileReader.onload = async function(event) {
						try {
							exporters = null;
							if (ed) {
								ed.innerHTML = "";
								ed.remove();
								ed = null;
							}
							data = null;
							sampleData = null;
							sampleSkip = 480;
							if (whichInterpret) {
								const data = event.target.result;
								const bits = Math.max(prompt("What is the bits per sample of the audio?") >> 3, 1);
								sharedBuffer = audioContext.createBuffer(1, data.byteLength / bits, prompt("What is the samplerate of the audio?"));
								const channel = sharedBuffer.getChannelData(0);
								const len = sharedBuffer.length;
								const buffer = new Uint8Array(data);
								if (bits === 1) {
									const bufferInt = new Int8Array(data);
									for (let i = 0; i < len; i++) {
										channel[i] = bufferInt[i] / 0x80;
									}
								} else if (bits === 2) {
									for (let i = 0, j = 0; i < len; i += bits, j++) {
										channel[j] = ((buffer[i + 1] << 8) | buffer[i]) / 0x8000 - 0.5;
									}
								} else if (bits === 3) {
									for (let i = 0, j = 0; i < len; i += bits, j++) {
										channel[j] = ((buffer[i + 2] << 16) | (buffer[i + 1] << 8) | buffer[i]) / 0x800000 - 0.5;
									}
								} else if (bits === 4) {
									for (let i = 0, j = 0; i < len; i += bits, j++) {
										channel[j] = ((buffer[i + 3] << 24) | (buffer[i + 2] << 16) | (buffer[i + 1] << 8) | buffer[i]) / 0x80000000 - 0.5;
									}
								}
								exporters = new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32);
								loadDiv(exporters);
								return;
							}
							sharedBuffer = await audioContext.decodeAudioData(event.target.result);
							const channelNum = Math.max(1, Math.min(+prompt("Which channel should be imported for editing? Pick a channel from 1 to " + sharedBuffer.numberOfChannels + ". (Editing multiple channels at once isn't an option due to the creator's preferred simplicity.)") || 1, sharedBuffer.numberOfChannels)) - 1;
							const channel = sharedBuffer.getChannelData(channelNum);
							if (sharedBuffer.numberOfChannels === 2) {
								if (confirm("Should the current channel be subtracted by another? (If you want to only edit the audio, just press Cancel)")) {
									const channelOtherNum = sharedBuffer.numberOfChannels - channelNum - 1;
									const len = channel.length;
									const channelOther = sharedBuffer.getChannelData(channelOtherNum);
									const choice = prompt("Okay then! Which formula do you want to choose? (0 = channel" + channelNum + " - otherChannel | 1 = channel" + channelNum + " * 2 - otherChannel | 2 = channel" + channelNum + " - (otherChannel - channel" + channelNum + ") / 2 | 3 = 2 but otherChannel" + channelNum + " * 2 | 4 = channel" + channelNum + " + otherChannel)") | 0;
									if (choice === 0) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i];
										}
									} else if (choice === 1) {
										for (let i = 0; i < len; i++) {
											channel[i] = channelOther[i] - channel[i];
										}
									} else if (choice === 2) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i] - channel[i];
										}
									} else if (choice === 3) {
										for (let i = 0; i < len; i++) {
											channel[i] -= channelOther[i] * 2 - channel[i];
										}
									} else if (choice === 4) {
										for (let i = 0; i < len; i++) {
											channel[i] = (channel[i] + channelOther[i]) * 0.5;
										}
									}
								}
							}
							if (sharedBuffer.numberOfChannels > 1) { // Normalize playback, since only one channel is being loaded. If other channels are playing while one is selected, it can suddenly sound "mono" if an effect is applied, which confuses the user
								for (let i = 0; i < sharedBuffer.numberOfChannels; i++) {
									if (i === channelNum) continue;
									const silentBuffer = sharedBuffer.getChannelData(i);
									if (silentBuffer) silentBuffer.set(channel);
								}
							}
							exporters = new AudioExporter(channel, sharedBuffer.sampleRate, 1, 32);
							loadDiv(exporters);
						} catch (err) {
							alert("The audio could not be properly loaded! We couldn't gather any info on what exactly failed, so the best we can say is: try selecting another audio file, or using another browser.");
							console.log(err.message + err.stack);
						}
					}
					fileReader.readAsArrayBuffer(firstFile);
				}
			}
			tick();
		</script>
	</body>
</html>
